<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-09-14T00:41:06-05:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Deylemma</title><subtitle>An Engineering Blog
</subtitle><author><name>Daniel Deychakiwsky</name><email>d.deychak@gmail.com</email></author><entry><title type="html">Generative Matchmaking</title><link href="http://localhost:4000/generative-matchmaking" rel="alternate" type="text/html" title="Generative Matchmaking" /><published>2023-09-09T00:00:00-05:00</published><updated>2023-09-09T00:00:00-05:00</updated><id>http://localhost:4000/generative-matchmaking</id><content type="html" xml:base="http://localhost:4000/generative-matchmaking">&lt;p&gt;This post details an AI-based matchmaking simulation
leveraging vector based semantic search for user 
compatibility recommendations and retrieval-augmented 
generation for co-personalized first-date ideation 
using OpenAI‚Äôs GPT-4, OpenAI‚Äôs DALL¬∑E-2, and Chroma, 
an AI-native open-source vector database.&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#elevator-pitch&quot; id=&quot;markdown-toc-elevator-pitch&quot;&gt;Elevator Pitch&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#simulation&quot; id=&quot;markdown-toc-simulation&quot;&gt;Simulation&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#generating-synthetic-users&quot; id=&quot;markdown-toc-generating-synthetic-users&quot;&gt;Generating Synthetic Users&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#profiles&quot; id=&quot;markdown-toc-profiles&quot;&gt;Profiles&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#images&quot; id=&quot;markdown-toc-images&quot;&gt;Images&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#matchmaking&quot; id=&quot;markdown-toc-matchmaking&quot;&gt;Matchmaking&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#recommender-system&quot; id=&quot;markdown-toc-recommender-system&quot;&gt;Recommender System&lt;/a&gt;            &lt;ul&gt;
              &lt;li&gt;&lt;a href=&quot;#chroma-vector-database&quot; id=&quot;markdown-toc-chroma-vector-database&quot;&gt;Chroma Vector Database&lt;/a&gt;                &lt;ul&gt;
                  &lt;li&gt;&lt;a href=&quot;#retrieval&quot; id=&quot;markdown-toc-retrieval&quot;&gt;Retrieval&lt;/a&gt;&lt;/li&gt;
                  &lt;li&gt;&lt;a href=&quot;#ranking&quot; id=&quot;markdown-toc-ranking&quot;&gt;Ranking&lt;/a&gt;&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#visualizing-matches&quot; id=&quot;markdown-toc-visualizing-matches&quot;&gt;Visualizing Matches&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#date-ideas&quot; id=&quot;markdown-toc-date-ideas&quot;&gt;Date Ideas&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#cost&quot; id=&quot;markdown-toc-cost&quot;&gt;Cost&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#literature-review&quot; id=&quot;markdown-toc-literature-review&quot;&gt;Literature Review&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;elevator-pitch&quot;&gt;Elevator Pitch&lt;/h1&gt;

&lt;p&gt;Popular dating services have converged to an experience
where users must swipe, match, chat, and plan to meet. 
For many users, this results in too much time spent
repeatedly swiping, small talking, and planning.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;I‚Äôm looking for a connection where I can simply ask, 
‚ÄúWould you like to meet up for drinks later?‚Äù 
I wish online dating could solely serve the purpose 
of arranging dates, eliminating the need for aimless small talk. 
Repeating the same text-based conversations that lead nowhere gets tiresome. 
Meeting in person right away would allow us to gauge our compatibility and save time. 
‚Äì &lt;cite&gt;I‚Äôm a 27-year-old female.&lt;/cite&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Inspired by the emergence of human-like behavior of modern AI, 
our vision is to present an experience where each user is paired 
with a personalized AI matchmaking assistant that 
can be reinforced with human feedback to align to changes in user preference
while working behind the scenes on behalf of the user 
by engaging with other user assistants to 
create harmonious matches so that users can spend less time searching
and more time meeting their people. We posit that this approach would 
minimize swipe time, eliminate small talk, and assist in planning.
The remainder of this post details a simulated subset of functionality
that plugs into the overall effort.&lt;/p&gt;

&lt;p&gt;üßë ‚Üí ü§ñüí¨ ‚Üí ‚ù§Ô∏è ‚Üê üí¨ü§ñ ‚Üê üßë&lt;/p&gt;

&lt;h1 id=&quot;simulation&quot;&gt;Simulation&lt;/h1&gt;

&lt;p&gt;The simulated implementation is made available in a public 
Github &lt;a href=&quot;https://github.com/daniel-deychakiwsky/generative-matchmaking&quot;&gt;repository&lt;/a&gt;.
As a proof-of-concept we generated
synthetic dating user profiles, pictures, 
and produced matches for each of them, all of which
are stored in the &lt;a href=&quot;https://github.com/daniel-deychakiwsky/generative-matchmaking/tree/master/profiles&quot;&gt;profiles&lt;/a&gt; directory.&lt;/p&gt;

&lt;h2 id=&quot;generating-synthetic-users&quot;&gt;Generating Synthetic Users&lt;/h2&gt;

&lt;h3 id=&quot;profiles&quot;&gt;Profiles&lt;/h3&gt;

&lt;p&gt;We sequentially generated 250 synthetic dating user profiles using OpenAI‚Äôs chat 
completion endpoint with the following configuration settings: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;model=&quot;gpt-4-0613&quot;&lt;/code&gt;, 
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_tokens=5000&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;temperature=1.05&lt;/code&gt;. Initially, our attempt to generate numerous dating 
profiles in a single inference pass, allowing the model to consider previously generated 
profiles for uniqueness and diversity, was hindered by output token limit constraints. 
To address this, we adopted an alternative approach: we chatted with the model
to generate a collection of names and subsequently instructed the model to sample from this pool
as a seed for profile generation.&lt;/p&gt;

&lt;p&gt;Our starting point was the default system prompt: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;You are a helpful assistant.&quot;&lt;/code&gt;. 
Within this conversation, we provided the instruction: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;Generate 10 unique first and 
last names, ensuring a balanced diversity.&quot;&lt;/code&gt; Following this, we issued a follow-up directive: 
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;Select a name randomly and create a dating profile for the chosen name.&quot;&lt;/code&gt;. It‚Äôs worth noting 
that the sampling process suffers from positional biases inherent in language models. 
Nevertheless, this strategy, at he very least, improved generation of a diverse set of names
across all users.&lt;/p&gt;

&lt;p&gt;For the generation of the dating profile, we utilized OpenAI‚Äôs function calling API, which 
produced a structured JSON response based on our dating profile &lt;a href=&quot;https://github.com/daniel-deychakiwsky/generative-matchmaking/blob/master/src/generative_matchmaking/llm/oai_function_schemas.py&quot;&gt;schema&lt;/a&gt; where 
we hardcoded the dating location to Los Angeles, California for all users. Note that
although our schema is basic, it can be updated to include other pieces of static or dynamic
information along with the concept of ‚Äúdealbreakers‚Äù which effectively translates
to a hard filter on specified partner preference attributes.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Developers can now describe functions to gpt-4-0613 and gpt-3.5-turbo-0613, 
and have the model intelligently choose to output a JSON object containing 
arguments to call those functions. 
This is a new way to more reliably connect GPT‚Äôs capabilities with external tools and APIs.
These models have been fine-tuned to both detect when a function needs to be 
called (depending on the user‚Äôs input) and to respond with JSON that 
adheres to the function signature. Function calling allows developers 
to more reliably get structured data back from the model. ‚Äì &lt;cite&gt;OpenAI docs.&lt;/cite&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Once the dating profile was generated we instructed to
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;Summarize the user's dating profile. 
Include all fields other than partner_preferences. Output a concise paragraph.&quot;&lt;/code&gt;
and finally to 
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;Summarize the user's dating partner_preferences. 
Include partner_preferences fields only and nothing else. Output a concise paragraph.&quot;&lt;/code&gt;
We did not include the user‚Äôs name in the summarization instruction context to maintain generality
across users.
An example synthetic dating profile follows.&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Mia Wong&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;age&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;29&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;height&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;5'6&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;school&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;University of California, Berkeley&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;job_industry&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Technology&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;job_title&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Software Engineer&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;hometown_location&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;San Francisco, California&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;dating_location&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Los Angeles, California&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;languages_spoken&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;English&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Mandarin&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;values&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Responsibility&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Family&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Ambition&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;interests&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Cooking&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Hiking&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Traveling&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;education_level&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Graduate&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;religious_beliefs&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Atheist&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;politics&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Liberal&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;dating_intentions&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Long term, open to short&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;relationship_type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Monogamy&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;gender&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Woman&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;pronouns&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;She/Her/Hers&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;sexuality&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Straight&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;ethnicity&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;East Asian&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;has_children&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;want_children&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;pets&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Cat&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;zodiac_sign&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Sagittarius&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;mbti_personality_type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;INTJ&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;drinking&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Sometimes&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;smoking&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;No&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;marijuana&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;No&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;drugs&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;No&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;exercise&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Active&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;partner_preferences&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;minimum_age&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;maximum_age&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;35&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;minimum_height&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;5'6&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;maximum_height&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;6'2&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;has_children&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;want_children&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;sexuality&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Straight&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;drinking&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Sometimes&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;smoking&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;No&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;marijuana&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;No&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;drugs&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;No&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;exercise&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Active&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;gender&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Man&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;dating_intentions&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Long term, open to short&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;relationship_type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Monogamy&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;ethnicities&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Black African Descent&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;East Asian&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Middle Eastern&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Native American&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Pacific Islander&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;South Asian&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Southeast Asian&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;White Caucasian&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;politics&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Liberal&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Not political&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;job_industry&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Technology&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Finance&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Consulting&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;languages_spoken&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;English&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;values&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Responsibility&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Family&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Ambition&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;interests&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Cooking&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Hiking&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Traveling&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;education_level&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Undergraduate&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Graduate&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;profile_summary&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;see below&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;preferences_summary&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;see below&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;user_id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;fce07a22-133b-46b9-b187-ca1ae5c0b70e&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Profile Summary&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;The user is a 29-year-old woman who identifies as straight. She uses she/her pronouns and is of 
East Asian ethnicity. She graduated from the University of California, Berkeley and now works 
as a Software Engineer in the technology industry. Originally from San Francisco, California, 
she is now looking to date in Los Angeles, California. She is an atheistic liberal who values 
responsibility, family, and ambition. She enjoys cooking, hiking, and traveling. Despite her 
busy schedule, she maintains an active lifestyle. She speaks both English and Mandarin fluently. 
She owns a cat and wishes to have children although she doesn't have any yet. She is a 
Sagittarius with an INTJ Myers-Briggs Type Indicator. An occasional drinker, she 
doesn't smoke or use marijuana or other drugs. Her intention is to be in a monogamous 
relationship, open to both long term commitments and causal dating.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Preferences Summary&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;The user is a woman who is interested in dating a man who is between the ages of 28 and 35, 
and between 5'6&quot; and 6'2&quot; in height. Her preferred partner would be someone who does not 
have children but is open to having some in the future. The partner should be straight, 
drinks occasionally, doesn't smoke or involve in marijuana or drugs. She prefers a man who 
is active and practices monogamy. Ethnicity- wise, her interests include a range of ethnic 
groups, from Black African Descent, East Asian, Middle Eastern, Native American, Pacific 
Islander, South Asian, Southeast Asian to White Caucasian. She prefers partners who identify 
as Liberal or are not political. The ideal match for her would work in the Technology, Finance, 
or Consulting industries. The primary language should be English. In terms of values, she looks 
for Responsibility, Family, Ambition, and shares interests in cooking, hiking and traveling. 
Potential partners should have at least an undergraduate level of education.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;images&quot;&gt;Images&lt;/h3&gt;

&lt;p&gt;We generated a user profile picture for every user by invoking OpenAI‚Äôs DALL¬∑E-2 
text-to-image model. We constructed the prompt by interpolating the following
template with several fields from the user dating profile schema. Originally, we included
the first and last name but OpenAI, rightly-so, flagged it as unsafe,
so we removed it. Note that the prompt for this model must stay under a shorter
character limit.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;prompt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Dating profile picture of a &quot;&lt;/span&gt;
    &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_profile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_profile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ethnicity&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_profile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; &quot;&lt;/span&gt;
    &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;year old &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_profile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gender&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; (&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_profile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pronouns&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;) &quot;&lt;/span&gt;
    &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;with an &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_profile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exercise&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; physique who works as a &quot;&lt;/span&gt;
    &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_profile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job_industry&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; professional &quot;&lt;/span&gt;
    &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;that values &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;' and '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_profile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; &quot;&lt;/span&gt;
    &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;who enjoys &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;' and '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_profile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;interests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; who &quot;&lt;/span&gt;
    &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;identifies as &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_profile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;religious_beliefs&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;.&quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here are 28 examples, the overall quality varies.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/generative_matchmaking/profile_0.png&quot; alt=&quot;img_0&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_1.png&quot; alt=&quot;img_1&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_2.png&quot; alt=&quot;img_2&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_3.png&quot; alt=&quot;img_3&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_4.png&quot; alt=&quot;img_4&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_5.png&quot; alt=&quot;img_5&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_6.png&quot; alt=&quot;img_6&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_7.png&quot; alt=&quot;img_7&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_8.png&quot; alt=&quot;img_8&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_9.png&quot; alt=&quot;img_9&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_10.png&quot; alt=&quot;img_10&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_11.png&quot; alt=&quot;img_11&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_12.png&quot; alt=&quot;img_12&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_13.png&quot; alt=&quot;img_13&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_14.png&quot; alt=&quot;img_14&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_15.png&quot; alt=&quot;img_15&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_16.png&quot; alt=&quot;img_16&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_17.png&quot; alt=&quot;img_17&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_18.png&quot; alt=&quot;img_18&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_19.png&quot; alt=&quot;img_19&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_20.png&quot; alt=&quot;img_20&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_21.png&quot; alt=&quot;img_21&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_22.png&quot; alt=&quot;img_22&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_23.png&quot; alt=&quot;img_23&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_24.png&quot; alt=&quot;img_24&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_25.png&quot; alt=&quot;img_25&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_26.png&quot; alt=&quot;img_26&quot; /&gt;
&lt;img src=&quot;/assets/images/generative_matchmaking/profile_27.png&quot; alt=&quot;img_27&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;matchmaking&quot;&gt;Matchmaking&lt;/h2&gt;

&lt;h3 id=&quot;recommender-system&quot;&gt;Recommender System&lt;/h3&gt;

&lt;p&gt;Mainstream dating apps train hybrid recommender systems that model content-based
and collaborative filtering effects based on a robust set of features
including explicit / implicit user interactions, e.g., swiping, time-on-page, etc.
Modern recommender systems are implemented as a conglomerate of
individual components that often treat retrieval and ranking as separate tasks.&lt;/p&gt;

&lt;p&gt;Researchers have shown that LLMs generalize as zero-shot recommenders but,
through ablation studies, found that they‚Äôre primarily content-based
and that they struggle with non-trivial ranking tasks, 
likely connected to their inherent positional bias.&lt;/p&gt;

&lt;p&gt;Since our study lacked human feedback to being with, we experimented with
a prompt based zero-shot retrieval mechanism but realized this approach
would not scale effectively due to context-window limits. Instead,
we implemented retrieval as semantic vector search. To rank the retrieved 
output, we experimented with prompt engineering the ranking task but 
the results clearly suffered from artifacts of positional bias. 
Although bootstrapping the ranking task alleviated some concern 
by reducing variance and thereby stabilizing rankings, 
the results did not suffice, so we chose to implement 
a graph inspired ranking heuristic.&lt;/p&gt;

&lt;h4 id=&quot;chroma-vector-database&quot;&gt;Chroma Vector Database&lt;/h4&gt;

&lt;p&gt;We spun up a local and persistent version of &lt;a href=&quot;https://www.trychroma.com/&quot;&gt;Chroma&lt;/a&gt;, 
an AI-native open-source vector database. By default, 
Chroma uses the Sentence Transformers &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;all-MiniLM-L6-v2&lt;/code&gt; 
model to create embeddings. This embedding model can create sentence and 
document embeddings that can be used for a wide variety of tasks. 
This embedding function runs locally, downloading and caching the model files.
We loaded every user‚Äôs &lt;strong&gt;profile summary&lt;/strong&gt;, as a document, 
into a &lt;em&gt;collection&lt;/em&gt; and tagged each entry with the user‚Äôs gender
and sexuality as &lt;em&gt;metadata&lt;/em&gt; for which we manually enforce as
‚Äúdealbreakers‚Äù or hard filters.&lt;/p&gt;

&lt;h5 id=&quot;retrieval&quot;&gt;Retrieval&lt;/h5&gt;

&lt;p&gt;Recall that we created two summaries for each user profile where we
summarized, &lt;em&gt;mutually exclusively&lt;/em&gt;, each user‚Äôs profile and their partner preferences.
To compute an initial set of candidates for a given user, we query the Chroma &lt;em&gt;collection&lt;/em&gt;
with a given user‚Äôs &lt;strong&gt;partner preference summary&lt;/strong&gt; and specify the hard filter based 
on the user‚Äôs partner preference gender and sexuality &lt;em&gt;metadata&lt;/em&gt;. Under the hood, Chroma
executes a similarity / distance lookup on the embedded query text and returns the
closest &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n_results&lt;/code&gt; or neighbors sorted by ascending distance. Choosing a distance metric and an
appropriate value for the number of neighbors are hyperparameters which can be tuned 
to the use case. We configured Chroma to use &lt;em&gt;cosine&lt;/em&gt; distance and return the 25 closest 
neighbors.&lt;/p&gt;

&lt;h5 id=&quot;ranking&quot;&gt;Ranking&lt;/h5&gt;

&lt;p&gt;The retrieved set of candidate user profiles for a given user can 
naively be surfaced as matches for human feedback but some of those
candidates may be better matches than others. Borrowing from graph theory, we defined
users as nodes and directed weighted edges as match-affinity 
between them. We built the graph by adding retrieval-distance 
weighted edges for every user-candidate pair of nodes connecting
a query user to that user‚Äôs retrieved candidate set.&lt;/p&gt;

&lt;p&gt;We defined compatibility as a bidirectional connection where a retrieved 
candidate user‚Äôs retrieved set of candidates includes the query user. 
These candidates, that point back to query user, are ranked higher than those that don‚Äôt. 
This can be thought of as one level of breadth-first search.
To illustrate, user $M$ is compatible with the ordered set of users 
$\{C, B, P\}$ in diagram that follows.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/generative_matchmaking/graph.png&quot; alt=&quot;graph&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;visualizing-matches&quot;&gt;Visualizing Matches&lt;/h3&gt;

&lt;p&gt;To visualize matches, we hacked together a user interface with directions
on how to run it outlined in the repo‚Äôs &lt;a href=&quot;https://github.com/daniel-deychakiwsky/generative-matchmaking/blob/master/README.md&quot;&gt;readme&lt;/a&gt;. A screenshot of Theodore Heath‚Äôs matches,
ranked from left-to-right, follows. The presence of an asterisk by the name of a 
match indicates bidirectional connection or compatibility.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/generative_matchmaking/ui.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The most compatible match recommended for Theodore Heath is Olivia Windsor.
Theodore and Olivia being marked as a compatible match means that
Theodore‚Äôs &lt;strong&gt;partner preference summary&lt;/strong&gt; is semantically similar to Olivia‚Äôs
&lt;strong&gt;profile summary&lt;/strong&gt; and that Olivia‚Äôs &lt;strong&gt;partner preference summary&lt;/strong&gt; is semantically
similar to Theodore‚Äôs &lt;strong&gt;profile summary&lt;/strong&gt; within the embedding geometry.
In other words, Theodore is looking for someone like Olivia and
Olivia is looking for someone like Theodore based on the information
available to us.
We can inspect Theodore and Olivia‚Äôs profile and partner preference 
summaries to qualitatively evaluate the match.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Theodore Profile Summary&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;This user is a 29-year-old Software Engineer in the Technology industry based in Los Angeles, 
California, but originally from San Francisco. He stands 6 feet tall and is a graduate from 
the California State University. He identifies as a straight white Caucasian man who uses 
the pronouns He/Him/His, with agnostic religious beliefs, and a moderate political stance. 
He values honesty, humor, and intelligence and enjoys outdoor activities, video games, and 
reading in his spare time. This user is a Pisces and his MBTI personality type is INTJ. 
Despite being occasionally up for a drink, he does not smoke or use drugs, including marijuana. 
He leads an active lifestyle and owns a dog. His desires for the future include having children, 
as he currently doesn't have any. He's also open to a long-term, monogamous relationship. 
His primary languages are English and Spanish.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Theodore Preferences Summary&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;The user is seeking a female partner aged 24 to 31 years who falls between the heights of 5'5&quot; 
and 6'0&quot;. She doesn't have children but must be open to having them in the future. An ideal 
match would be a straight woman who occasionally drinks but doesn't smoke or use marijuana or 
other drugs. Light to moderate exercise habits are preferred. Ethnicity-wise, he is open to 
dating women of both White Caucasian and Hispanic/Latino backgrounds. In terms of political 
inclination, he prefers a woman with moderate views. Professionally, he prefers women working 
in the Education, Technology, or Healthcare industry. Fluency in English is a must, and he 
values Honesty, Kindness, and Intelligence. Shared interests might include outdoor activities, 
music, or reading. Education is important too, with a preference for woman who have at least 
an undergraduate degree or higher. He is looking for a long-term relationship that is monogamous.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Olivia‚Äôs Profile Summary&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;This user is a 28 year-old woman standing at 5'6&quot;. She is a UX Designer working in the tech 
industry and is a graduate of Stanford University. She identifies as straight and is interested 
in a monogamous, long-term relationship. Originally from New York, New York, she is currently 
dating in Los Angeles, California. She fluently speaks English and Spanish, and identifies her 
ethnicity as white caucasian. Her core values are creativity, independence, and adventure. 
Interests include photography, cooking, and travel. She identifies as agnostic and liberal. 
Although she doesn't have any children yet, she wants them in the future. She is an active 
drinker but doesn't smoke, use marijuana, or drugs. When it comes to exercise, she's quite active. 
She owns a cat and is a Gemini with an ENFP personality type.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Olivia‚Äôs Preferences Summary&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;The user is looking for a man who is between the ages of 28 and 35 and stands between 5'8&quot; 
and 6'2&quot;. He shouldn't have children currently but should want to have them in the future. 
Ideally, he would be straight, an active individual, and a non-smoker. He's preferred to be 
someone who has no problems with drinking but doesn't use marijuana or any other drugs. In 
terms of ethnicity, he can be of any listed ethnicity. Politically, a liberal or moderate man 
would be suitable. The ideal man would work in either Tech, Finance, or Health sectors, and 
English should be among his languages. He should value kindness, honesty, and be committed. 
His interests should include hiking, photography, and travelling. The user prefers someone who 
has at least an undergraduate level of education.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;date-ideas&quot;&gt;Date Ideas&lt;/h2&gt;

&lt;p&gt;// TODO&lt;/p&gt;

&lt;h1 id=&quot;cost&quot;&gt;Cost&lt;/h1&gt;

&lt;p&gt;// TODO&lt;/p&gt;

&lt;h1 id=&quot;literature-review&quot;&gt;Literature Review&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2203.02155.pdf&quot;&gt;https://arxiv.org/pdf/2203.02155.pdf&lt;/a&gt; (OpenAI)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2304.03442.pdf&quot;&gt;https://arxiv.org/pdf/2304.03442.pdf&lt;/a&gt; (Stanford)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2306.02707.pdf&quot;&gt;https://arxiv.org/pdf/2306.02707.pdf&lt;/a&gt; (Microsoft)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2305.10601.pdf&quot;&gt;https://arxiv.org/pdf/2305.10601.pdf&lt;/a&gt; (Google)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2201.11903.pdf&quot;&gt;https://arxiv.org/pdf/2201.11903.pdf&lt;/a&gt; (Google)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2308.10053.pdf&quot;&gt;https://arxiv.org/pdf/2308.10053.pdf&lt;/a&gt; (Netflix)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2305.08845.pdf&quot;&gt;https://arxiv.org/pdf/2305.08845.pdf&lt;/a&gt; (Netflix)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2305.07622.pdf&quot;&gt;https://arxiv.org/pdf/2305.07622.pdf&lt;/a&gt; (Amazon)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2005.11401v4.pdf&quot;&gt;https://arxiv.org/pdf/2005.11401v4.pdf&lt;/a&gt; (Meta)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2303.11366.pdf&quot;&gt;https://arxiv.org/pdf/2303.11366.pdf&lt;/a&gt; (MIT)&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Daniel Deychakiwsky</name></author><category term="machine-learning" /><category term="artificial-intelligence" /><summary type="html">This post details an AI-based matchmaking simulation leveraging vector based semantic search for user compatibility recommendations and retrieval-augmented generation for co-personalized first-date ideation using OpenAI‚Äôs GPT-4, OpenAI‚Äôs DALL¬∑E-2, and Chroma, an AI-native open-source vector database.</summary></entry><entry><title type="html">Open Foundation AI Models - Meta‚Äôs Llama2-7B-Chat</title><link href="http://localhost:4000/open-foundation-ai-models-metas-llama-2-7b-chat" rel="alternate" type="text/html" title="Open Foundation AI Models - Meta‚Äôs Llama2-7B-Chat" /><published>2023-08-13T00:00:00-05:00</published><updated>2023-08-13T00:00:00-05:00</updated><id>http://localhost:4000/open-foundation-ai-models-metas-llama-2-7b-chat</id><content type="html" xml:base="http://localhost:4000/open-foundation-ai-models-metas-llama-2-7b-chat">&lt;p&gt;This post shares practical learnings
from experimenting with Meta‚Äôs
Llama-2-7B-Chat LLM via HuggingFace APIs
quantized to FP16 on a 16 CPU CORE, 60GB CPU MEM, and 
16GB GPU MEM hardware instance.&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#open-shout-out&quot; id=&quot;markdown-toc-open-shout-out&quot;&gt;Open Shout Out&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#learnings&quot; id=&quot;markdown-toc-learnings&quot;&gt;Learnings&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#license&quot; id=&quot;markdown-toc-license&quot;&gt;License&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#huggingface-variations&quot; id=&quot;markdown-toc-huggingface-variations&quot;&gt;HuggingFace Variations&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#hardware&quot; id=&quot;markdown-toc-hardware&quot;&gt;Hardware&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#model-loading&quot; id=&quot;markdown-toc-model-loading&quot;&gt;Model Loading&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#model-tokenizer&quot; id=&quot;markdown-toc-model-tokenizer&quot;&gt;Model Tokenizer&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#chat-prompt-template&quot; id=&quot;markdown-toc-chat-prompt-template&quot;&gt;Chat Prompt Template&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#model-generation&quot; id=&quot;markdown-toc-model-generation&quot;&gt;Model Generation&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#remarks&quot; id=&quot;markdown-toc-remarks&quot;&gt;Remarks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;open-shout-out&quot;&gt;Open Shout Out&lt;/h1&gt;

&lt;p&gt;The third industrial revolution of digitizing information 
was built on top of open source software (OSS) technologies, e.g., 
Linux, HTTP server, Nginx, Kubernetes, Hadoop, Postgres, 
etc. The fourth and current industrial revolution of 
artificial intelligence (AI) is of no exception. Meta‚Äôs initiative
to open its latest suite of large language models (LLMs), branded as Llama 2,
was a push in the right direction. I suspect their current head of AI, 
Yann LeCun, had a lot to do with it! Apart from his fascinating recent
publications on self-supervised world models, he‚Äôs been publicly pushing
for opening AI to the masses.&lt;/p&gt;

&lt;h1 id=&quot;learnings&quot;&gt;Learnings&lt;/h1&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;I won‚Äôt cover the model in detail since this post focuses on
the practicals, however, some basic info follows.
&lt;a href=&quot;https://arxiv.org/pdf/2307.09288.pdf&quot;&gt;Llama 2&lt;/a&gt; is an auto-regressive language model from Meta that
uses an improved &lt;a href=&quot;https://arxiv.org/pdf/1706.03762.pdf&quot;&gt;transformer&lt;/a&gt; architecture.
It was released in a range of parameter sizes: 7B, 13B, and 70B, available 
in both pretrained and chat fine-tuned variations with a context
window size of 4096 tokens.&lt;/p&gt;

&lt;h2 id=&quot;license&quot;&gt;License&lt;/h2&gt;

&lt;p&gt;To get access to download the model weights 
you‚Äôll need to accept the Llama 2 Community
License Agreement by submitting a &lt;a href=&quot;https://ai.meta.com/resources/models-and-libraries/llama-downloads/&quot;&gt;request&lt;/a&gt;. 
For those deploying on-prem at a larger organizations,
read each clause carefully.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Additional Commercial Terms. 
If, on the Llama 2 version release date, 
the monthly active users of the products or 
services made available by or for Licensee, or Licensee‚Äôs affiliates, 
is greater than 700 million monthly active users in the preceding calendar month, 
you must request a license from Meta, which Meta may grant to you in its sole discretion, 
and you are not authorized to exercise any of the rights under this Agreement unless 
or until Meta otherwise expressly grants you such rights.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;huggingface-variations&quot;&gt;HuggingFace Variations&lt;/h2&gt;

&lt;p&gt;To keep my costs floored, I chose to experiment with the smallest
chat fine-tuned variation made available through the HF model &lt;a href=&quot;https://huggingface.co/meta-llama/Llama-2-7b-chat-hf&quot;&gt;hub&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;hardware&quot;&gt;Hardware&lt;/h2&gt;

&lt;p&gt;My hardware constraints were:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;16 CPU CORES&lt;/li&gt;
  &lt;li&gt;60GB CPU MEM&lt;/li&gt;
  &lt;li&gt;16GB GPU MEM (One Nvidia Tesla T4)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Serving a 7B parameter model in full precision @ FP32 would require
$4 * 7000000000 = 28000000000$ Bytes or 28GB of GPU MEM. 
I quantized the precision and instead loaded the model
@ FP16 which required $2 * 7000000000 = 14000000000$ or 14GB of GPU MEM. 
That was good enough to satisfy the hardware constraints 
with a small amount of head-room for experimental input inference.&lt;/p&gt;

&lt;h2 id=&quot;model-loading&quot;&gt;Model Loading&lt;/h2&gt;

&lt;p&gt;HF offers several methods for loading models. Two popular choices are 
their high-level pipeline abstraction or the direct model loader. 
I chose the latter. 
They &lt;a href=&quot;https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/tree/main&quot;&gt;host&lt;/a&gt; model weights in two storage formats, python pickled
(.bin) and a newer format called safetensors (.safetensors). 
The &lt;a href=&quot;https://huggingface.co/docs/safetensors/index&quot;&gt;safetensor&lt;/a&gt; format is my preference for all the reasons it exists.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;transformers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AutoTokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AutoModelForCausalLM&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;model_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;meta-llama/Llama-2-7b-chat-hf&quot;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AutoTokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pretrained_model_name_or_path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_path&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AutoModelForCausalLM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pretrained_model_name_or_path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;use_safetensors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;torch_dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float16&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;That downloads the model from the hub, caches it on disk, and loads it into CPU MEM @ FP16 
where I observed an expected allocation of ~14GB of CPU MEM.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/open_foundation_ai_models_metas_llama_2_7b_chat/cpu_0.png&quot; alt=&quot;cpu_0&quot; /&gt;&lt;/p&gt;

&lt;p&gt;HF‚Äôs &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;from_pretrained&lt;/code&gt; is flexible. Among others, it 
optionally accepts several interesting parameters: &lt;em&gt;low_cpu_mem_usage&lt;/em&gt;, &lt;em&gt;max_memory&lt;/em&gt;, 
&lt;em&gt;offload_folder&lt;/em&gt;, and &lt;em&gt;device_map&lt;/em&gt;. Most of those offer a bit of control over memory management.
The &lt;em&gt;device_map&lt;/em&gt; parameter can be used alongside HF &lt;a href=&quot;https://huggingface.co/docs/accelerate/index&quot;&gt;Accelerate&lt;/a&gt;
to optimally and automatically make use of underlying visible hardware. This is handy for
multi GPU settings and when a given model can‚Äôt fit into a single GPU.
Let‚Äôs proceed to manually move the model to the GPU.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'cuda'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The model is now loaded into GPU MEM and removed from CPU MEM where I observed
an expected drop in CPU MEM utilization and an allocation of ~14GB GPU MEM.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/open_foundation_ai_models_metas_llama_2_7b_chat/cpu_1.png&quot; alt=&quot;cpu_1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nvidia-smi&lt;/code&gt; command prints GPU utilization information.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/open_foundation_ai_models_metas_llama_2_7b_chat/gpu_0.png&quot; alt=&quot;gpu_0&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;model-tokenizer&quot;&gt;Model Tokenizer&lt;/h2&gt;

&lt;p&gt;LLMs often use special tokens during training to partition sequences of varying length
within the context window and during batching. Interesting that the typical 
padding token is not included. Since I‚Äôm running batchless inference and not training / fine-tuning, 
I kept it unset.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;special_tokens_map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# {'bos_token': '&amp;lt;s&amp;gt;', 'eos_token': '&amp;lt;/s&amp;gt;', 'unk_token': '&amp;lt;unk&amp;gt;'}
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bos_token_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 1
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eos_token_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 2
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unk_token_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 0
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad_token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Using pad_token, but it is not set yet.
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad_token_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# None
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Unless specified otherwise, the tokenizer will add special tokens to the input
query. I disabled that behavior because the chat fine-tuned version of this model 
requires a special prompt template that I wanted full control over. The
tokenized input can be moved to the GPU with the same command.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Hey how are you?'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;input_ids&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;return_tensors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'pt'&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'input_ids'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'cuda'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# tensor([[    1, 18637,   920,   526,   366, 29973]], device='cuda:0')
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_ids&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;add_special_tokens&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;return_tensors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'pt'&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'input_ids'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'cuda'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# tensor([[18637,   920,   526,   366, 29973]], device='cuda:0')
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;chat-prompt-template&quot;&gt;Chat Prompt Template&lt;/h2&gt;

&lt;p&gt;The chat prompt template researches used during fine-tuning should be applied during inference
as &lt;a href=&quot;https://huggingface.co/blog/llama2&quot;&gt;outlined&lt;/a&gt; by the HF team and by Meta‚Äôs generation &lt;a href=&quot;https://github.com/facebookresearch/llama/blob/main/llama/generation.py#L212&quot;&gt;routine&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;s&amp;gt;[INST] &amp;lt;&amp;lt;SYS&amp;gt;&amp;gt;
{ system_prompt }
&amp;lt;&amp;lt;/SYS&amp;gt;&amp;gt;

{ user_msg_1 } [/INST] { model_answer_1 } &amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;[INST] { user_msg_2 } [/INST]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The model is stateless. That means it doesn‚Äôt remember the conversation
as it is happening so the client must accumulate the conversation as it progresses
and pass it as context on every forward pass. I wrote a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ChatPrompt&lt;/code&gt; class 
that accumulates the dialogue and builds the prompt template.
The system prompt is optional but recommended. Two issues persist that I haven‚Äôt patched
in this demo. The first is saturation of the model‚Äôs context window. 
Capping the conversation at a set token limit or applying one of 
LangChain‚Äôs &lt;a href=&quot;https://python.langchain.com/docs/modules/memory/types/&quot;&gt;conversation memory types&lt;/a&gt; would do the trick. The second is saturation of GPU MEM. 
As the conversation grows, it will be tokenized and must fit into GPU MEM during the forward pass
or a CUDA OOM error will be thrown. That comes down to tuning hardware and / or capping inputs.
Notice that the special tokens that I suppressed in the tokenizer, I‚Äôve manually added
to the prompt.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;typing&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Set&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;role&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;role&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;role&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ChatPrompt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# special tokens
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;B_SEN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;s&amp;gt;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;E_SEN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;/s&amp;gt;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;B_INS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;[INST]&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;E_INS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;[/INST]&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;B_SYS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;&amp;lt;SYS&amp;gt;&amp;gt;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;E_SYS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;&amp;lt;/SYS&amp;gt;&amp;gt;&quot;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# format tokens
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;N_L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W_S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; &quot;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# role names
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;R_S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;S&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;R_U&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;U&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;R_A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;A&quot;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# role turns
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;R_TURN_MAP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R_U&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R_U&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R_A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R_A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R_U&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;R_INIT_SET&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R_U&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;system_message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conversation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;system_message&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;system_message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;system_message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conversation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;system_message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;role&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_validate_turns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conversation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Exception&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Conversation is empty&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;role&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conversation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;role&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;role&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_INIT_SET&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Exception&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Invalid first role&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conversation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;role&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_TURN_MAP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;role&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Exception&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Invalid role turn&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;role&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;role&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_validate_messages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conversation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Exception&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Conversation is empty&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conversation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Exception&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Invalid message&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;validate_conversation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_validate_turns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_validate_messages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;add_user_message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;message&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conversation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;role&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_U&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;add_assistant_message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;message&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conversation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;role&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;validate_conversation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;prompt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;has_system_message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conversation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;role&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_S&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;closed_system_message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conversation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;role&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;prompt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                    &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;B_SEN&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}{&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;B_INS&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}{&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W_S&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
                    &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;B_SYS&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}{&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N_L&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}{&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N_L&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
                    &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E_SYS&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}{&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N_L&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}{&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N_L&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;role&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_U&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;has_system_message&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;closed_system_message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;prompt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}{&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W_S&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}{&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E_INS&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;closed_system_message&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;prompt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                        &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;B_SEN&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}{&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;B_INS&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}{&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W_S&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
                        &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}{&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W_S&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}{&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E_INS&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
                    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;role&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;prompt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W_S&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}{&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W_S&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}{&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E_SEN&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prompt&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;test_chat_prompt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;chat_prompt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ChatPrompt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ChatPrompt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;system_message&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;System&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;chat_prompt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_user_message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;User message 1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;chat_prompt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_assistant_message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Assistant message 1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;chat_prompt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_user_message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;User message 2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;chat_prompt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_assistant_message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Assistant message 2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;a_prompt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;chat_prompt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;e_prompt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;s&amp;gt;[INST] &amp;lt;&amp;lt;SYS&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;System&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;&amp;lt;/SYS&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;User message 1 [/INST] &quot;&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;Assistant message 1 &quot;&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;[INST] &quot;&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;User message 2 [/INST] &quot;&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;Assistant message 2 &quot;&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;/s&amp;gt;&quot;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a_prompt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e_prompt&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;chat_prompt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ChatPrompt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ChatPrompt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;chat_prompt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_user_message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;User message 1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;chat_prompt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_assistant_message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Assistant message 1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;chat_prompt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_user_message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;User message 2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;a_prompt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;chat_prompt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;e_prompt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;s&amp;gt;[INST] &quot;&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;User message 1 [/INST] &quot;&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;Assistant message 1 &quot;&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;/s&amp;gt;&amp;lt;s&amp;gt;[INST] &quot;&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;User message 2 [/INST]&quot;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a_prompt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e_prompt&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;__main__&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;test_chat_prompt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;model-generation&quot;&gt;Model Generation&lt;/h2&gt;

&lt;p&gt;A smoke test forward pass never hurts. I didn‚Äôt include the prompt template or any fancy
prompt engineering / in-context learning. I was expecting a subpar response.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Hey! How are you?'&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;input_ids&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;add_special_tokens&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;return_tensors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'pt'&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'input_ids'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'cuda'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;generate_kwargs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'input_ids'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'num_return_sequences'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'max_new_tokens'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'do_sample'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'use_cache'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'num_beams'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'top_p'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.95&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'top_k'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'temperature'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'repetition_penalty'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'length_penalty'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;output_ids&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;generate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;generate_kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;skip_special_tokens&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;'''
[&quot;Hey! How are you?&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Answer: &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;em{Hey! I'm doing great, 
thanks for asking! How about you? It's been a while since 
we last spoke, how have you been? üòä}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;This response shows 
that you are interested in the other person's well-being and 
are willing to engage in small talk. It also helps to break 
the ice and establish a friendly tone for the conversation.&quot;]
'''&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;A careful inspector of the output would notice that the model parroted back
the input prompt within its response. I learned that the community handles this 
by applying a &lt;em&gt;repetition_penalty&lt;/em&gt; or by truncating the input from the output
as seen in HF‚Äôs text-generation pipeline &lt;a href=&quot;https://github.com/huggingface/transformers/blob/main/src/transformers/pipelines/text_generation.py#L305&quot;&gt;implementation&lt;/a&gt;. I felt that penalizing the model
for repetition for this use case was suboptimal. I implemented the latter. Here‚Äôs a 
sample conversation applying my &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ChatPrompt&lt;/code&gt; utility to build the accumulated prompt
initialized with a custom system message on every forward pass.
To clarify the role turns, I‚Äôm Daniel and I named the assistant (LLM) Trinity because 
I‚Äôm a Matrix fan.&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;System: Your name is Trinity. You are a helpful, respectful and honest assistant. 
Always answer as helpfully as possible, while being safe. 
Your answers should not include any harmful, unethical, 
racist, sexist, toxic, dangerous, or illegal content. 
Please ensure that your responses are socially unbiased and positive in nature. 
If a question does not make any sense, or is not factually coherent, 
explain why instead of answering something not correct. 
If you don't know the answer to a question, please don't share false information.

Daniel: Hey! What's your name?

Trinity: Hello! My name is Trinity, and I'm here to help you with any 
questions or concerns you may have. It's important to me that my responses are always safe, 
respectful, and socially unbiased, so please feel free to ask me anything. 
Is there something specific you would like to know or discuss?

Daniel: Recommend one restaurant in San Diego, California for tacos.

Trinity: Ah, San Diego, home to some of the best tacos in the world! 
üòã There are so many amazing taco spots in SD, but if I had to recommend just one, 
I would have to go with... (drumroll please)... La Taqueria! üéâ
Located in the heart of North Park, La Taqueria has been serving up some of the most delicious, 
authentic Mexican food in the city for over 20 years. Their tacos are made with fresh, 
handmade tortillas, filled with only the freshest ingredients, and cooked to perfection. 
From classic carne asada and carnitas to more adventurous options like the 
&quot;Taco de lengua&quot; (beef tongue) and the &quot;Taco de camar√≥n&quot; (shrimp), there's 
something for every taco lover at La Taqueria. üåÆ
But don't just take my word for it! La Taqueria has been consistently ranked as one 
of the best taco spots in San Diego by locals and visitors alike. And with a cozy, 
casual atmosphere and friendly service, you'll feel right at home the moment you step inside. üòä
So if you're in San Diego and craving some amazing tacos, do yourself a favor 
and head on over to La Taqueria. Your taste buds (and your taco cravings) will thank you! üôèüèºüåÆ

Daniel: I don't like beef tongue.

Trinity: No problem! La Taqueria has plenty of other delicious taco options to choose from. 
Here are some of their popular tacos that don't include beef tongue:
1. Carne Asada: Thinly sliced grilled steak, served with fresh cilantro, onion, and salsa.
2. Carnitas: Slow-cooked pork, shredded and fried until crispy, served with fresh salsa, lime, and cilantro.
3. Pollo Asado: Marinated grilled chicken, served with fresh cilantro, onion, and salsa.
4. Al Pastor: Thinly sliced marinated pork, served with fresh cilantro, onion, and pineapple.
5. Veggie: Grilled vegetables, including onions, bell peppers, and mushrooms, served with fresh 
salsa and guacamole.

All of these options are delicious and authentic, and you can't go wrong with any of them! 
So, which one will you choose? ü§î
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;remarks&quot;&gt;Remarks&lt;/h1&gt;

&lt;p&gt;One criticism I have on the Llama 2 model suite is that it &lt;strong&gt;overly&lt;/strong&gt; errs on the side of caution. 
I‚Äôve observed it confuse human-deemed safe instructions as queries for toxic or unsafe response
generation. This may be the result of some form of overfitting to the massive investment of 
aligning the model to human preferences. The paper outlines the details. Two reward signals!&lt;/p&gt;

&lt;p&gt;Nevertheless, it‚Äôs an exciting time to be alive. 
There‚Äôs a new ground-breaking AI research paper shaking
things up on a weekly basis. I‚Äôm most excited for world models and audio / video modality 
diffusion based generation evolution. Commercially open AI systems are growing in number 
and useful tools are being built on top of them that are transforming humanity.&lt;/p&gt;</content><author><name>Daniel Deychakiwsky</name></author><category term="machine-learning" /><category term="artificial-intelligence" /><summary type="html">This post shares practical learnings from experimenting with Meta‚Äôs Llama-2-7B-Chat LLM via HuggingFace APIs quantized to FP16 on a 16 CPU CORE, 60GB CPU MEM, and 16GB GPU MEM hardware instance.</summary></entry><entry><title type="html">Matrix Factorization Sparsity</title><link href="http://localhost:4000/matrix-factorization-sparsity" rel="alternate" type="text/html" title="Matrix Factorization Sparsity" /><published>2022-01-02T00:00:00-06:00</published><updated>2022-01-02T00:00:00-06:00</updated><id>http://localhost:4000/matrix-factorization-sparsity</id><content type="html" xml:base="http://localhost:4000/matrix-factorization-sparsity">&lt;p&gt;This post explores how implicit user-item interaction sparsity poses
a challenge for matrix factorization (model-based) collaborative filtering
recommender systems.&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#primer&quot; id=&quot;markdown-toc-primer&quot;&gt;Primer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#matrix-factorization&quot; id=&quot;markdown-toc-matrix-factorization&quot;&gt;Matrix Factorization&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#sparsity&quot; id=&quot;markdown-toc-sparsity&quot;&gt;Sparsity&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#problematic&quot; id=&quot;markdown-toc-problematic&quot;&gt;Problematic?&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#simulations&quot; id=&quot;markdown-toc-simulations&quot;&gt;Simulations&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;primer&quot;&gt;Primer&lt;/h1&gt;

&lt;p&gt;This post assumes understanding of the general &lt;em&gt;recommendations&lt;/em&gt;
machine learning (ML) problem, basic modeling approaches,
and commonly used evaluation metrics.
For a refresher, check out Google‚Äôs recommender systems mini-&lt;a href=&quot;https://developers.google.com/machine-learning/recommendation/collaborative/basics&quot;&gt;course&lt;/a&gt;
which introduces Content-Based Filtering (CBF),
Collaborative Filtering (CF) with Matrix Factorization (MF),
and Deep Neural Networks (DNN). The remainder of this post 
focuses on MF for &lt;strong&gt;sparse implicit&lt;/strong&gt; user-item interactions.&lt;/p&gt;

&lt;h1 id=&quot;matrix-factorization&quot;&gt;Matrix Factorization&lt;/h1&gt;

&lt;p&gt;CF with MF is a type of model-based (parametric) algorithm that
decomposes $\mathbf{V}$ (user-item interaction matrix)
into a product of two matrices, $\mathbf{W}$ (latent user embeddings)
and $\mathbf{H}$ (latent item embeddings), by minimizing
some flavor of reconstruction error. Although MF is
inherently linear, it is a ‚Äútried and true‚Äù technique 
that is often reported to produce serendipitous recommendations.&lt;/p&gt;

\[\mathbf{W}\mathbf{H}^\top \approx \mathbf{V}
\tag{1} \label{1}\]

&lt;p&gt;The algorithm exposes a hyperparameter that serves to expand or
contract the dimensionality of the columns in $\mathbf{W}$ 
and the rows in $\mathbf{H}$. It can be set so that $\mathbf{W}$ and 
$\mathbf{H}$ become low-rank factors of $\mathbf{V}$, 
&lt;strong&gt;forcing a compressed encoding that captures latent structure&lt;/strong&gt;
(important information) for approximating $\mathbf{V}$.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/matrix_factorization_sparsity/mf.png&quot; alt=&quot;mf&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;sparsity&quot;&gt;Sparsity&lt;/h1&gt;

&lt;p&gt;At production grade scale it‚Äôs common to produce recommendations
for millions of users and items based off of sparse implicit 
interactions, e.g., purchases, streams, etc.&lt;/p&gt;

&lt;p&gt;Imagine a scenario with just $24$ unique items and $24$ unique users.
If each user purchased 3 unique items, the number of 
non-zeros in this interaction matrix is $24 * 3 = 72$
while the remaining $(24 ‚àó 24) - 72 = 504$ entries are all zeros.
That‚Äôs a sparsity of $1 - (72 / (24 * 24)) = 0.875$. In other words, 
$87.5\%$ of the interaction matrix entries are zeros.&lt;/p&gt;

\[\begin{bmatrix}
0 &amp;amp;  0  &amp;amp; \ldots &amp;amp; 0\\
0  &amp;amp;  1 &amp;amp; \ldots &amp;amp; 0\\
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\\
1  &amp;amp;   0       &amp;amp;\ldots &amp;amp; 0
\end{bmatrix}
\tag{2} \label{2}\]

&lt;p&gt;MF models are fairly resilient 
but extreme cases can become problematic.
It‚Äôs common to subsample (users and / or items) and / or collect 
multi-channel interaction data (from other implicit data 
sources, e.g., time-on-page) in hopes of reducing sparsity. 
Even after applying user subsampling,
authors of the noteworthy Neural Collaborative Filtering (&lt;a href=&quot;https://arxiv.org/pdf/1708.05031.pdf&quot;&gt;NCF&lt;/a&gt;)
research reported a sparsity of $99.73\%$ on Pinterest data.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The original data is very large but highly sparse. 
For example, over 20% of users have only one pin, making it difficult
to evaluate collaborative filtering algorithms. As such, we
filtered the dataset in the same way as the MovieLens data
that retained only users with at least 20 interactions (pins).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;problematic&quot;&gt;Problematic?&lt;/h2&gt;

&lt;p&gt;ML models are only as good as the data that powers them
and MF is no exception to that rule. To demonstrate why sparsity
is a problem, let‚Äôs consider a thought experiment.&lt;/p&gt;

&lt;p&gt;We‚Äôll continue with the scenario from above, $24$ users and $24$ items, 
but add an evil twist so that each user has purchased only one
distinct item that no other user has purchased. We could reorder the
users (rows of the interaction matrix) to arrive at the 
identity matrix, i.e., the canonical orthonormal basis $\in \mathbb{R}^{24\times24}$
that is linearly independent by definition. In other words, there isn‚Äôt
much to learn as the unit vectors point in orthogonal directions.&lt;/p&gt;

\[\mathbf{I}_{24} =
\begin{bmatrix}
1 &amp;amp;  0  &amp;amp; \ldots &amp;amp; 0\\
0  &amp;amp;  1 &amp;amp; \ldots &amp;amp; 0\\
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\\
0  &amp;amp;   0       &amp;amp;\ldots &amp;amp; 1
\end{bmatrix}
\tag{3} \label{3}\]

&lt;p&gt;If we train the model with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;factors=24&lt;/code&gt; 
(the hyperparameter discussed earlier), what do you think 
the model learns to do? It ends up learning exactly what it‚Äôs
supposed to; its best reconstruction of the interaction (identity)
matrix and it does so by &lt;strong&gt;inverting the item factor matrix&lt;/strong&gt;.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;implicit.als&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mf&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scipy.sparse&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sp&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AlternatingLeastSquares&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;csr_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eye&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;allclose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_factors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item_factors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;atol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# True
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

\[\mathbf{W}(\mathbf{H}^\top)^{-1} \approx \mathbf{I}
\tag{4} \label{4}\]

&lt;p&gt;Although the inversion is obvious given $\mathbf{W} \in \mathbb{R}^{24\times24}$, 
$\mathbf{H} \in \mathbb{R}^{24\times24}$, and $\mathbf{I}_{24}$, this degenerate case 
highlights how helpless the model becomes with no correlation or interesting 
signal in the data.&lt;/p&gt;

&lt;h2 id=&quot;simulations&quot;&gt;Simulations&lt;/h2&gt;

&lt;p&gt;Speaking of ‚Äúsignals‚Äù and ‚Äúcorrelations‚Äù, the user-item interaction matrix
is exactly that. In practice, the interactions we observe follow some natural
generative process. If we knew the process we wouldn‚Äôt need the model.&lt;/p&gt;

&lt;p&gt;Let‚Äôs generate a synthetic interaction matrix by stacking &lt;a href=&quot;https://en.wikipedia.org/wiki/Sine_wave&quot;&gt;sine waves&lt;/a&gt;.
Here‚Äôs what a $1$, $2$, and $3$ Hz sine wave sampled at $1$ kHz look like.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/matrix_factorization_sparsity/sine_waves.png&quot; alt=&quot;sine_waves&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We start with a $1$ Hz sine wave and layer its
harmonics (integer multiple increasing frequencies)
along the row index. By holding the sampling rate 
constant at $25$ Hz, we intentionally undersample 
the harmonics above the Nyquist frequency 
producing a non-random symmetric pattern 
induced by the waves and their aliases.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/matrix_factorization_sparsity/interactions.png&quot; alt=&quot;interactions&quot; /&gt;&lt;/p&gt;

&lt;p&gt;By quantizing the amplitudes to $\{0, 1\}$, 
we end up with a bitmap that we‚Äôll use as our
interaction matrix. Note that entries in the 
interaction matrix are not limited to discrete 
values.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;interactions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endpoint&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# remove first row and col - looks better
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;interactions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delete&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;interactions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;interactions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delete&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;interactions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;interactions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;interactions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;interactions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;interactions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/matrix_factorization_sparsity/interactions_bitmap.png&quot; alt=&quot;interactions_bitmap&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The spirals that emerge from the sine waves‚Äô auto
and harmonic correlations jump out because
the brain is a pattern recognition (correlating)
machine. Don‚Äôt you think you could get close to drawing it
just by looking at it for a few seconds?
The sparsity of this matrix is $51.3\%$, about half 
of the entries are non-zeros. Since it is noticeably 
correlated and not relatively 
sparse, this will be trivial for MF - but what if we
started loosing signal, literally, by randomly zeroing
out non-zero entries and thereby increasing sparsity?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/matrix_factorization_sparsity/interactions_removed.png&quot; alt=&quot;interactions_removed&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Let‚Äôs run a monte-carlo simulation to investigate. We‚Äôll make it
even easier by equipping the model with more than enough parameters by
sticking with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;factors=24&lt;/code&gt; (from above) so that the model is free to
factorize the square interaction matrix into two other square matrices 
instead of two lower-rank matrices. We‚Äôll report performance using 
standard ranking@10 evaluation metrics against a random $80\%-20\%$ 
train-test split.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;implicit.als&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mf&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;implicit.evaluation&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ev&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scipy.sparse&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sp&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;n_users&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;n_items&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;n_factors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;n_sim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;n_el&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_users&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_items&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sparsities&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.91&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sparsity&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sparsities&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ranking_metrics&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_sim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;interactions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_el&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sparsity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;r_z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;choice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_el&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unravel_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r_z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_users&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;trn_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tst_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;csr_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AlternatingLeastSquares&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_factors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trn_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;show_progress&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ranking_metrics_at_k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trn_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tst_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;show_progress&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ranking_metrics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ranking_metrics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/matrix_factorization_sparsity/sparsity_sim.png&quot; alt=&quot;sparsity_sim&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Initially, the model performs well as the factorization
problem is less complex and the matrix is dense. As sparsity increases and 
the signal in the data is corrupted, the
average performance decreases with increasing variability.&lt;/p&gt;

&lt;p&gt;Let‚Äôs try this again but make the problem 
harder by shuffling the rows of the interaction
matrix that we synthesized in the previous step.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/matrix_factorization_sparsity/interactions_shuffled.png&quot; alt=&quot;interactions_shuffled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/matrix_factorization_sparsity/sparsity_sim_shuffled.png&quot; alt=&quot;sparsity_sim_shuffled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Initially, the model doesn‚Äôt perform as well when the matrix is dense because
the shuffle operation decorrelates the data a priori.
The remaining trend is similar to the previous but with an increase in overall variability.&lt;/p&gt;</content><author><name>Daniel Deychakiwsky</name></author><category term="machine-learning" /><category term="artificial-intelligence" /><summary type="html">This post explores how implicit user-item interaction sparsity poses a challenge for matrix factorization (model-based) collaborative filtering recommender systems.</summary></entry><entry><title type="html">Low Energy Audio Segments</title><link href="http://localhost:4000/low-energy-audio-segments" rel="alternate" type="text/html" title="Low Energy Audio Segments" /><published>2021-03-21T00:00:00-05:00</published><updated>2021-03-21T00:00:00-05:00</updated><id>http://localhost:4000/low-energy-audio-segments</id><content type="html" xml:base="http://localhost:4000/low-energy-audio-segments">&lt;p&gt;This post outlines a simple algorithm for
identifying low energy audio segments.
This post assumes basic knowledge of digital 
signal processing (DSP).&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#digital-signal-processing-dsp&quot; id=&quot;markdown-toc-digital-signal-processing-dsp&quot;&gt;Digital Signal Processing (DSP)&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#root-mean-square-rms&quot; id=&quot;markdown-toc-root-mean-square-rms&quot;&gt;Root Mean Square (RMS)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#amplitude-envelope-ae&quot; id=&quot;markdown-toc-amplitude-envelope-ae&quot;&gt;Amplitude Envelope (AE)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#ae--rms&quot; id=&quot;markdown-toc-ae--rms&quot;&gt;AE + RMS&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#demo&quot; id=&quot;markdown-toc-demo&quot;&gt;Demo&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#fig-1&quot; id=&quot;markdown-toc-fig-1&quot;&gt;Fig. 1&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#fig-2&quot; id=&quot;markdown-toc-fig-2&quot;&gt;Fig. 2&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#fig-3&quot; id=&quot;markdown-toc-fig-3&quot;&gt;Fig. 3&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#improvements&quot; id=&quot;markdown-toc-improvements&quot;&gt;Improvements&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;digital-signal-processing-dsp&quot;&gt;Digital Signal Processing (DSP)&lt;/h1&gt;

&lt;p&gt;If you don‚Äôt know DSP, I‚Äôd suggest taking a few
courses to learn it as the applications are endless. Coursera offers
exceptional &lt;a href=&quot;https://www.coursera.org/learn/dsp1&quot;&gt;foundational&lt;/a&gt; and useful &lt;a href=&quot;https://www.coursera.org/learn/audio-signal-processing&quot;&gt;music applications&lt;/a&gt; courses.
In addition, I recommend checking out Jack Schaedler‚Äôs compact &lt;a href=&quot;https://jackschaedler.github.io/circles-sines-signals/&quot;&gt;primer&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;root-mean-square-rms&quot;&gt;Root Mean Square (RMS)&lt;/h2&gt;

&lt;p&gt;We will use &lt;a href=&quot;https://en.wikipedia.org/wiki/Root_mean_square#Definition&quot;&gt;RMS&lt;/a&gt; to proxy the de facto time-domain signal &lt;a href=&quot;https://en.wikipedia.org/wiki/Energy_(signal_processing)&quot;&gt;energy&lt;/a&gt; calculation.
They measure different spins of approximately the same thing,
the $L^2$ or &lt;a href=&quot;https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm&quot;&gt;euclidean norm&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In order to see how RMS changes over time we can
apply a framed version of the calculation yielding a new signal
which captures how the RMS of our signal changes over time.&lt;/p&gt;

&lt;p&gt;When I say ‚Äúframed‚Äù I mean we‚Äôre considering $n$ audio samples
in a single calculation, storing the result, shifting or hopping over by
$m$ samples, and then repeating the process until we traverse the entire signal.&lt;/p&gt;

&lt;p&gt;Why not just use a framed version of the energy calculation?
I‚Äôm using RMS because a framed version of it is already implemented
in the audio package I‚Äôm importing. Work smart, not hard :).&lt;/p&gt;

&lt;h2 id=&quot;amplitude-envelope-ae&quot;&gt;Amplitude Envelope (AE)&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Envelope_(waves)&quot;&gt;AE&lt;/a&gt; is also a framed calculation and is simply the maximum value of a given frame.
This can be interpreted as measuring a spin of the $L^\infty$ or &lt;a href=&quot;https://en.wikipedia.org/wiki/Uniform_norm&quot;&gt;infinity norm&lt;/a&gt;.
Its calculation yields a signal that traces the upper envelope of the original signal over time.
Valerio Velardo‚Äôs &lt;a href=&quot;https://www.youtube.com/watch?v=rlypsap6Wow&quot;&gt;implementation&lt;/a&gt; is all we need.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;amplitude_envelope&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([]),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frame_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2048&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hop_length&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ae&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frame_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hop_length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;ae--rms&quot;&gt;AE + RMS&lt;/h2&gt;

&lt;p&gt;We combine these two measures to form our final algorithm. We set the
frame and hop sizes that will be shared by both measures and carry out the calculations.
We use the AE as our measure of how the signal‚Äôs energy changes over time,
and the standard deviation of the framed RMS as the threshold.&lt;/p&gt;

&lt;p&gt;Everytime the AE dips below the standard deviation of the framed RMS,
we mark the beginning of a potential segment. Once it breaks back over the threshold,
we mark the end of a segment and add that segment to
a temporary result buffer. Once we‚Äôve done this for the entire AE, we sort the segments
by the length of the segment, descending.&lt;/p&gt;

&lt;h2 id=&quot;demo&quot;&gt;Demo&lt;/h2&gt;

&lt;p&gt;Here‚Äôs some fake audio with its waveform:&lt;/p&gt;

&lt;audio controls=&quot;&quot;&gt;
  &lt;source src=&quot;/assets/audio/low_energy_audio_segments/fake_audio.mp3&quot; type=&quot;audio/mpeg&quot; /&gt;
  Your browser does not support the audio element.
&lt;/audio&gt;

&lt;h4 id=&quot;fig-1&quot;&gt;Fig. 1&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;assets/images/low_energy_audio_segments/fake_audio.png&quot; alt=&quot;fake_audio&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here‚Äôs the same fake audio waveform with the aforementioned calculations overlaid:&lt;/p&gt;

&lt;h4 id=&quot;fig-2&quot;&gt;Fig. 2&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;assets/images/low_energy_audio_segments/fake_audio_result.png&quot; alt=&quot;fake_audio_result&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#fig-2&quot;&gt;Fig 2.&lt;/a&gt; shows the time-domain waveform in blue,
the AE in red, RMS in pink, +/- one standard deviation of
RMS in yellow, and three segment midpoints found in green
where thickness indicates a longer low energy segment.&lt;/p&gt;

&lt;p&gt;Here‚Äôs something a bit less basic, a &lt;a href=&quot;https://en.wikipedia.org/wiki/Mel_scale#:~:text=The%20mel%20scale%20(after%20the,dB%20above%20the%20listener's%20threshold.&quot;&gt;mel&lt;/a&gt;-&lt;a href=&quot;https://en.wikipedia.org/wiki/Spectrogram#:~:text=A%20spectrogram%20is%20a%20visual,they%20may%20be%20called%20waterfalls.&quot;&gt;spectrogram&lt;/a&gt; of the fake audio:&lt;/p&gt;

&lt;h4 id=&quot;fig-3&quot;&gt;Fig. 3&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;assets/images/low_energy_audio_segments/fake_audio_spec.png&quot; alt=&quot;fake_audio_spec&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Comparing &lt;a href=&quot;#fig-2&quot;&gt;Fig 2.&lt;/a&gt; to &lt;a href=&quot;#fig-3&quot;&gt;Fig 3.&lt;/a&gt;,
energy lacking in the time-domain corresponds to 
energy lacking in the frequency-domain.
Low-to-no speaking energy, as conveyed by low
amplitudes in the time-domain, corresponds
to a lack of vocal harmonics in the
frequency-domain. This conservation of energy between
domains is formally captured by &lt;a href=&quot;https://en.wikipedia.org/wiki/Parseval%27s_theorem&quot;&gt;Parseval‚Äôs theorem&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;improvements&quot;&gt;Improvements&lt;/h2&gt;

&lt;p&gt;There are infinite improvements that can be made. The algorithm is as basic as it gets and is
certainly overfitting to a specific type of audio. In some cases it will suffice 
to hand-engineer additional information, e.g., human &lt;a href=&quot;https://en.wikipedia.org/wiki/Voice_frequency&quot;&gt;voice frequency&lt;/a&gt; (voice band) detection. 
In other cases, manually engineering features will have less-of, if any effect at all
(think background music). I believe the more robust solutions will result from applied 
ML / AI / RL algorithms that are able to generalize to a broader spectrum of audio, 
of course, requiring larger amounts quality data.&lt;/p&gt;</content><author><name>Daniel Deychakiwsky</name></author><category term="digital-signal-processing" /><summary type="html">This post outlines a simple algorithm for identifying low energy audio segments. This post assumes basic knowledge of digital signal processing (DSP).</summary></entry><entry><title type="html">Ordinary Least Squares is Orthogonal Projection</title><link href="http://localhost:4000/linear-regression-is-orthogonal-projection" rel="alternate" type="text/html" title="Ordinary Least Squares is Orthogonal Projection" /><published>2020-12-08T00:00:00-06:00</published><updated>2020-12-08T00:00:00-06:00</updated><id>http://localhost:4000/linear-regression-is-orthogonal-projection</id><content type="html" xml:base="http://localhost:4000/linear-regression-is-orthogonal-projection">&lt;p&gt;This post visualizes the equivalence of two perspectives
on estimating the unknown parameters in a simple linear
regression model, ordinary least squares (OLS) and
orthogonal projection (OP).&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#context&quot; id=&quot;markdown-toc-context&quot;&gt;Context&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#ols--op&quot; id=&quot;markdown-toc-ols--op&quot;&gt;OLS &amp;amp; OP&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#the-big-picture&quot; id=&quot;markdown-toc-the-big-picture&quot;&gt;The Big Picture&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#fig-1&quot; id=&quot;markdown-toc-fig-1&quot;&gt;Fig. 1&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#toy-dataset&quot; id=&quot;markdown-toc-toy-dataset&quot;&gt;Toy Dataset&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#fig-2&quot; id=&quot;markdown-toc-fig-2&quot;&gt;Fig. 2&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#ols-perspective&quot; id=&quot;markdown-toc-ols-perspective&quot;&gt;OLS Perspective&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#fig-3&quot; id=&quot;markdown-toc-fig-3&quot;&gt;Fig. 3&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#fig-4&quot; id=&quot;markdown-toc-fig-4&quot;&gt;Fig. 4&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#op-perspective&quot; id=&quot;markdown-toc-op-perspective&quot;&gt;OP Perspective&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#fig-5&quot; id=&quot;markdown-toc-fig-5&quot;&gt;Fig. 5&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#fig-6&quot; id=&quot;markdown-toc-fig-6&quot;&gt;Fig. 6&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#fig-7&quot; id=&quot;markdown-toc-fig-7&quot;&gt;Fig. 7&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#desmos&quot; id=&quot;markdown-toc-desmos&quot;&gt;Desmos&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;context&quot;&gt;Context&lt;/h2&gt;

&lt;p&gt;In order to get more out of this post, you may want to brush up on:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Wikipedias on &lt;a href=&quot;https://en.wikipedia.org/wiki/Ordinary_least_squares&quot;&gt;ordinary least squares&lt;/a&gt;, &lt;a href=&quot;https://en.wikipedia.org/wiki/Vector_projection&quot;&gt;vector projection&lt;/a&gt;,
$L^2$ &lt;a href=&quot;https://en.wikipedia.org/wiki/Norm_(mathematics)&quot;&gt;norm&lt;/a&gt;, and (&lt;a href=&quot;https://en.wikipedia.org/wiki/Minimum_mean_square_error&quot;&gt;minimum&lt;/a&gt;) &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_squared_error&quot;&gt;mean squared error&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/@vladimirmikulik/why-linear-regression-is-a-projection-407d89fd9e3a&quot;&gt;Vladimir Mikulik‚Äôs post&lt;/a&gt; on ‚ÄúWhy Linear Regression
is a projection‚Äù.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/@andrew.chamberlain/the-linear-algebra-view-of-least-squares-regression-f67044b7f39b&quot;&gt;Andrew Chamberlain‚Äôs post&lt;/a&gt; on
‚ÄúThe Linear Algebra View of Least-Squares Regression‚Äù.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;ols--op&quot;&gt;OLS &amp;amp; OP&lt;/h2&gt;

&lt;h3 id=&quot;the-big-picture&quot;&gt;The Big Picture&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;#fig-1&quot;&gt;Fig 1.&lt;/a&gt; is a compact and interactive
&lt;a href=&quot;https://www.desmos.com/calculator/4fy0c4u3qt&quot;&gt;visualization&lt;/a&gt; that superimposes the two perspectives modeling a
&lt;a href=&quot;#toy-dataset&quot;&gt;toy dataset&lt;/a&gt;. The remainder of this post examines
each perspective in greater detail.&lt;/p&gt;

&lt;h4 id=&quot;fig-1&quot;&gt;Fig. 1&lt;/h4&gt;

&lt;iframe src=&quot;https://www.desmos.com/calculator/4fy0c4u3qt?embed&quot; width=&quot;500px&quot; height=&quot;500px&quot; style=&quot;border: 1px solid #ccc&quot; frameborder=&quot;0&quot;&gt;
&lt;/iframe&gt;

&lt;h3 id=&quot;toy-dataset&quot;&gt;Toy Dataset&lt;/h3&gt;

&lt;p&gt;For ease of intuition, our toy dataset is kept simple and
low-dimensional; just two data points $\in \mathbb{R}^2$.&lt;/p&gt;

&lt;p&gt;As column vectors:&lt;/p&gt;

\[\mathbf{x}_1 = \begin{bmatrix}2 \\ 1\end{bmatrix}
\quad \textrm{and} \quad
\mathbf{x}_2 = \begin{bmatrix}3 \\ 3\end{bmatrix}
\tag{1} \label{1}\]

&lt;p&gt;As a matrix:&lt;/p&gt;

\[\mathbf{X} = \begin{bmatrix}2 &amp;amp; 3 \\ 1 &amp;amp; 3\end{bmatrix}
\tag{2} \label{2}\]

&lt;h4 id=&quot;fig-2&quot;&gt;Fig. 2&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/linear_regression_is_orthogonal_projection/toy_data_x.png&quot; alt=&quot;toy_data_x&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#fig-2&quot;&gt;Fig 2.&lt;/a&gt; shows how the vector representations
(\ref{1}) translate to the cartesian plane as the
first dimension represents the canonical $x$-axis
while the second dimension represents the
canonical $y$-axis.&lt;/p&gt;

&lt;h3 id=&quot;ols-perspective&quot;&gt;OLS Perspective&lt;/h3&gt;

&lt;p&gt;In the context of machine learning,
it is common to view OLS linear regression
as a &lt;a href=&quot;https://en.wikipedia.org/wiki/Supervised_learning&quot;&gt;supervised learning&lt;/a&gt; problem.
Here‚Äôs a hand-wavy :) overview.&lt;/p&gt;

&lt;p&gt;The model is presented inputs for which
it makes corresponding predictions (outputs).
An error signal is calculated by aggregating the squared difference
of the model‚Äôs outputs against corresponding ‚Äútrue‚Äù values that have been
observed or are known a priori (a.k.a. labels).
Hence the term ‚Äúsupervised‚Äù, the error signal is used to correct
(as a teacher often corrects a student) the model parameters.
This training routine loops until the
model parameters converge. By minimizing the error signal,
the model learns optimal parameters.&lt;/p&gt;

\[x=2.0
\\
y=1.0
\\
\hat{y} = f(x;\beta) = 1.2
\\
err(y, \hat{y}) = (1.0 - 1.2)^2
\tag{3} \label{3}\]

&lt;p&gt;\ref{3} shows a hypothetical example of a single instance
error calculation, $err$, for some model input, $x$,
some model prediction (output),
$\hat{y}$; a linear function of $x$ parameterized by $\beta$,
and some label, $y$.&lt;/p&gt;

&lt;p&gt;On top of our already simplified dataset, we‚Äôll also simplify model
complexity by omitting the bias/intercept term, i.e., restricting our model
to only &lt;em&gt;one learnable parameter&lt;/em&gt;. Let‚Äôs train the model.&lt;/p&gt;

&lt;h4 id=&quot;fig-3&quot;&gt;Fig. 3&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.linear_model&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LinearRegression&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LinearRegression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_intercept&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'weights/parameters'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;weights/parameters array([[0.84615385]])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;#fig-3&quot;&gt;Fig 3.&lt;/a&gt; prints the resulting parameters (just one in our case)
of an OLS &lt;a href=&quot;https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html&quot;&gt;LinearRegression&lt;/a&gt; implementation written in Python using
a popular machine-learning Python package (&lt;a href=&quot;https://scikit-learn.org/stable/&quot;&gt;scikit-learn&lt;/a&gt;) after being
fit to (learning) our &lt;a href=&quot;#toy-dataset&quot;&gt;toy dataset&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;fig-4&quot;&gt;Fig. 4&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/linear_regression_is_orthogonal_projection/ols_regression_fit.png&quot; alt=&quot;ols_regression_fit&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#fig-4&quot;&gt;Fig 4.&lt;/a&gt; shows the OLS linear regression model fit to our
&lt;a href=&quot;#toy-dataset&quot;&gt;toy dataset&lt;/a&gt;. The hyperplane (line of best fit)
has a slope of $0.84615385$ as expected per output of &lt;a href=&quot;#fig-3&quot;&gt;Fig 3.&lt;/a&gt;
If we didn‚Äôt omit the bias/intercept term and we
let the model learn another degree of freedom (another parameter),
the solution would yield a hyperplane that fits the data perfectly,
i.e., the hyperplane would be free to adjust itself to interpolate
(intersect) exactly both data points. See &lt;a href=&quot;https://en.wikipedia.org/wiki/Polynomial_interpolation&quot;&gt;polynomial interpolation&lt;/a&gt;
for proof of uniqueness.&lt;/p&gt;

&lt;p&gt;How does all of that translate to OP? Let‚Äôs take a look.&lt;/p&gt;

&lt;h3 id=&quot;op-perspective&quot;&gt;OP Perspective&lt;/h3&gt;

&lt;p&gt;Here‚Äôs another hand-wavy :) overview.&lt;/p&gt;

&lt;p&gt;The learning process under the lens of OP
reduces to solving a system of linear equations;
so we‚Äôll need to frame
our &lt;a href=&quot;#toy-dataset&quot;&gt;toy dataset&lt;/a&gt; as such by vectorizing the linear model, e.g.,
the model‚Äôs outputs will be a linear function of the inputs
and the learned parameters. We can represent our model inputs and
labels as vectors $\in \mathbb{R}^2$.&lt;/p&gt;

\[\mathbf{y}_1 = \begin{bmatrix}2 \\ 3\end{bmatrix}
\quad \textrm{and} \quad
\mathbf{y}_2 = \begin{bmatrix}1 \\ 3\end{bmatrix}
\tag{4} \label{4}\]

&lt;p&gt;To disambiguate \ref{1} from \ref{4}, note that
$\mathbf{y}_1$ consists of the first dimensions of $\mathbf{x}_1$
and $\mathbf{x}_2$ while $\mathbf{y}_2$ consists of the second
dimensions of $\mathbf{x}_1$ and $\mathbf{x}_2$. In other words,
$\mathbf{y}_1$ is a vector of our model inputs and $\mathbf{y}_2$
is a vector of our model labels.&lt;/p&gt;

&lt;h4 id=&quot;fig-5&quot;&gt;Fig. 5&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/linear_regression_is_orthogonal_projection/toy_data_x_y.png&quot; alt=&quot;toy_data_x_y&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#fig-5&quot;&gt;Fig 5.&lt;/a&gt; shows how \ref{1} and \ref{4},
together, translate to the cartesian plane.&lt;/p&gt;

&lt;p&gt;The equation we need to solve to model our data is:&lt;/p&gt;

\[\mathbf{y}_1\boldsymbol{\beta} \approx \mathbf{y}_2
\tag{5} \label{5}\]

&lt;p&gt;It‚Äôs best practice to validate the shapes of the
matrices/vectors when operating on them.
$\mathbf{y}_1$ is $2 \times 1$, $\boldsymbol{\beta}$ is $1 \times 1$,
(recall that we‚Äôre omitting the bias/intercept term),
and so $\mathbf{y}_2$ checks out to be $2 \times 1$.&lt;/p&gt;

&lt;p&gt;Intuitively, \ref{5} tells us that $\mathbf{y}_2$ is
&lt;strong&gt;approximately&lt;/strong&gt; equal to a scaled version
of $\mathbf{y}_1$ and that scaling factor is our
learned parameter in $\boldsymbol{\beta}$.
The approximation is important because
$\mathbf{y}_1\boldsymbol{\beta} = \mathbf{y}_2$
&lt;strong&gt;will only be true if&lt;/strong&gt; $\mathbf{y}_2$ can be exactly
expressed as a scaled version of $\mathbf{y}_1$.
In practice this is seldom true. In our example,
it certainly isn‚Äôt (see &lt;a href=&quot;#fig-6&quot;&gt;Fig 6.&lt;/a&gt;).&lt;/p&gt;

&lt;h4 id=&quot;fig-6&quot;&gt;Fig. 6&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/linear_regression_is_orthogonal_projection/scaled_vector.png&quot; alt=&quot;scaled_vector&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#fig-6&quot;&gt;Fig 6.&lt;/a&gt; shows a subset of scaled versions
of $\mathbf{y}_1$ with the dashed green line and one randomly
chosen realization with the orange mark. That line
actually extends to infinity in both directions making up
a &lt;a href=&quot;https://en.wikipedia.org/wiki/Linear_subspace&quot;&gt;vector subspace&lt;/a&gt;. Notice how $\mathbf{y}_2$ does not fall
within that subspace? This is why we need to &lt;strong&gt;approximate&lt;/strong&gt;
a solution to the system and why we used the $\approx$
symbol in \ref{5}.&lt;/p&gt;

&lt;p&gt;It turns out that the best approximation we can get
is the OP of $\mathbf{y}_2$ onto $\mathbf{y}_1$‚Äôs subspace.
Omitting mathematical proofs, let‚Äôs visualize that claim.
We can define the distance from $\mathbf{y}_2$ to $\mathbf{y}_1$‚Äôs
subspace as a function of some scalar (in this example, a vector with one entry),
$\boldsymbol{\beta}$, which computes the distance from
$\mathbf{y}_2$ to a scaled version of $\mathbf{y}_1$.&lt;/p&gt;

\[\delta(\boldsymbol{\beta}) =
euclidean\_distance(\mathbf{y}_2, \boldsymbol{\beta} \cdot \mathbf{y}_1)
\tag{6} \label{6}\]

&lt;h4 id=&quot;fig-7&quot;&gt;Fig. 7&lt;/h4&gt;

&lt;iframe src=&quot;https://www.desmos.com/calculator/irvesdja2w?embed&quot; width=&quot;500px&quot; height=&quot;500px&quot; style=&quot;border: 1px solid #ccc&quot; frameborder=&quot;0&quot;&gt;
&lt;/iframe&gt;

&lt;p&gt;&lt;a href=&quot;#fig-7&quot;&gt;Fig 7.&lt;/a&gt; shows the distance function, $\delta(\boldsymbol{\beta})$,
and corresponding input-output tuple, ($\boldsymbol{\beta}, \delta(\boldsymbol{\beta})$),
in red; of some difference-vector, in dotted orange.
The difference-vector is the vector between $\mathbf{y}_2$ and some vector
(varied, indicated by the orange dotted line and mark)
falling within $\mathbf{y}_1$‚Äôs subspace. Notice that
the distance function is minimized when the difference-vector
is orthogonal to $\mathbf{y}_1$‚Äôs subspace. &lt;strong&gt;The
value of $\boldsymbol{\beta}$, at the minimum is $0.84615385$, exactly the
same solution observed in &lt;a href=&quot;#fig-3&quot;&gt;Fig 3.&lt;/a&gt; and &lt;a href=&quot;#fig-4&quot;&gt;Fig 4.&lt;/a&gt;&lt;/strong&gt;
with OLS.&lt;/p&gt;

&lt;p&gt;The term ‚Äúregression‚Äù has a concrete definition in the field of
statistics but what does it mean to ‚Äúregress‚Äù one variable ‚Äúonto/against‚Äù
another? My answer is OP. In this example we ‚Äúregressed‚Äù our
dependent variable, encoded as $\mathbf{y}_2$, ‚Äúonto/against‚Äù our 
explanatory variable, encoded as $\mathbf{y}_1$.&lt;/p&gt;

&lt;p&gt;In hindsight, this duality may not come as such a surprise after all.
If we consider the objective function from each perspective, they
both seek to minimize a similar, if not the same, &lt;em&gt;thing&lt;/em&gt;. The only
difference is how the problem is framed. I‚Äôll leave it up to you
as the reader to make the comparison between &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_squared_error&quot;&gt;mean squared error&lt;/a&gt;
and the $L^2$ &lt;a href=&quot;https://en.wikipedia.org/wiki/Norm_(mathematics)&quot;&gt;norm&lt;/a&gt; of the difference-vector, i.e.,
$||\mathbf{y}_2 - \boldsymbol{\beta} \cdot \mathbf{y}_1||_2$. The differences
come from applying normalizing constants and/or monotonic transformations,
both of which have no effect on minimization.&lt;/p&gt;

&lt;p&gt;Stitching all of that together, we can circle back to
&lt;a href=&quot;#fig-1&quot;&gt;Fig 1.&lt;/a&gt; and watch the two perspectives ‚Äúmove‚Äù together.
Hopefully now, it is easier to interpret and makes for an
elegant visualization.&lt;/p&gt;

&lt;h2 id=&quot;desmos&quot;&gt;Desmos&lt;/h2&gt;

&lt;p&gt;I built the visualizations for this post with &lt;a href=&quot;https://www.desmos.com/&quot;&gt;Desmos&lt;/a&gt;,
an incredible graphing web application that enables
users to visualize, study, and learn mathematics.&lt;/p&gt;</content><author><name>Daniel Deychakiwsky</name></author><category term="machine-learning" /><category term="artificial-intelligence" /><summary type="html">This post visualizes the equivalence of two perspectives on estimating the unknown parameters in a simple linear regression model, ordinary least squares (OLS) and orthogonal projection (OP).</summary></entry><entry><title type="html">Normalized Cross-Entropy</title><link href="http://localhost:4000/normalized-cross-entropy" rel="alternate" type="text/html" title="Normalized Cross-Entropy" /><published>2020-05-29T00:00:00-05:00</published><updated>2020-05-29T00:00:00-05:00</updated><id>http://localhost:4000/normalized-cross-entropy</id><content type="html" xml:base="http://localhost:4000/normalized-cross-entropy">&lt;p&gt;This post explores a normalized version of binary cross-entropy loss in attempt to 
remove the effect of the prior (class imbalance within the dataset) on the resulting value.&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#context&quot; id=&quot;markdown-toc-context&quot;&gt;Context&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#definition&quot; id=&quot;markdown-toc-definition&quot;&gt;Definition&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#facebook-research&quot; id=&quot;markdown-toc-facebook-research&quot;&gt;Facebook research&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#variables&quot; id=&quot;markdown-toc-variables&quot;&gt;Variables&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#equation&quot; id=&quot;markdown-toc-equation&quot;&gt;Equation&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#what-is-log-loss&quot; id=&quot;markdown-toc-what-is-log-loss&quot;&gt;What is log-loss?&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#probability-theory-derivation&quot; id=&quot;markdown-toc-probability-theory-derivation&quot;&gt;Probability Theory derivation&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#bernoulli&quot; id=&quot;markdown-toc-bernoulli&quot;&gt;Bernoulli&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#binomial&quot; id=&quot;markdown-toc-binomial&quot;&gt;Binomial&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#information-theory-derivation&quot; id=&quot;markdown-toc-information-theory-derivation&quot;&gt;Information Theory derivation&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#information-content&quot; id=&quot;markdown-toc-information-content&quot;&gt;Information content&lt;/a&gt;            &lt;ul&gt;
              &lt;li&gt;&lt;a href=&quot;#why-the-inverse-probability&quot; id=&quot;markdown-toc-why-the-inverse-probability&quot;&gt;Why the inverse probability?&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#why-the-logarithmic-transform&quot; id=&quot;markdown-toc-why-the-logarithmic-transform&quot;&gt;Why the logarithmic transform?&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#entropy&quot; id=&quot;markdown-toc-entropy&quot;&gt;Entropy&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#cross-entropy&quot; id=&quot;markdown-toc-cross-entropy&quot;&gt;Cross-entropy&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#kullbackleibler-divergence&quot; id=&quot;markdown-toc-kullbackleibler-divergence&quot;&gt;Kullback‚ÄìLeibler divergence&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#minimizing-cross-entropy--kullbackleibler-divergence&quot; id=&quot;markdown-toc-minimizing-cross-entropy--kullbackleibler-divergence&quot;&gt;Minimizing cross-entropy / Kullback‚ÄìLeibler divergence&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#cross-entropy-loss&quot; id=&quot;markdown-toc-cross-entropy-loss&quot;&gt;Cross-entropy loss&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#visualizing&quot; id=&quot;markdown-toc-visualizing&quot;&gt;Visualizing‚Ä¶&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#log-loss--cross-entropy&quot; id=&quot;markdown-toc-log-loss--cross-entropy&quot;&gt;Log-loss / cross-entropy&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#fig-1&quot; id=&quot;markdown-toc-fig-1&quot;&gt;Fig. 1&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#normalized-log-loss--cross-entropy&quot; id=&quot;markdown-toc-normalized-log-loss--cross-entropy&quot;&gt;Normalized log-loss / cross-entropy&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#click-through-rate-entropy&quot; id=&quot;markdown-toc-click-through-rate-entropy&quot;&gt;Click-through rate entropy&lt;/a&gt;            &lt;ul&gt;
              &lt;li&gt;&lt;a href=&quot;#fig-2&quot; id=&quot;markdown-toc-fig-2&quot;&gt;Fig. 2&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#fig-3&quot; id=&quot;markdown-toc-fig-3&quot;&gt;Fig. 3&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#fig-4&quot; id=&quot;markdown-toc-fig-4&quot;&gt;Fig. 4&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#baseline-model&quot; id=&quot;markdown-toc-baseline-model&quot;&gt;Baseline model&lt;/a&gt;            &lt;ul&gt;
              &lt;li&gt;&lt;a href=&quot;#fig-5&quot; id=&quot;markdown-toc-fig-5&quot;&gt;Fig. 5&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#fig-6&quot; id=&quot;markdown-toc-fig-6&quot;&gt;Fig. 6&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#fig-7&quot; id=&quot;markdown-toc-fig-7&quot;&gt;Fig. 7&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#fig-8&quot; id=&quot;markdown-toc-fig-8&quot;&gt;Fig. 8&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#fig-9&quot; id=&quot;markdown-toc-fig-9&quot;&gt;Fig. 9&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#fig-10&quot; id=&quot;markdown-toc-fig-10&quot;&gt;Fig. 10&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#fig-11&quot; id=&quot;markdown-toc-fig-11&quot;&gt;Fig. 11&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#fig-12&quot; id=&quot;markdown-toc-fig-12&quot;&gt;Fig. 12&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#special-thanks&quot; id=&quot;markdown-toc-special-thanks&quot;&gt;Special Thanks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#references&quot; id=&quot;markdown-toc-references&quot;&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;context&quot;&gt;Context&lt;/h2&gt;

&lt;p&gt;A common machine-learning task within the advertising domain is modeling user-ad click propensity.&lt;/p&gt;

\[P(click \space | \space user,ad)
\tag 1 \label 1\]

&lt;p&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Occam%27s_razor&quot;&gt;Occam‚Äôs Razor&lt;/a&gt; problem solving approach tells us that starting out with a simple model
is usually a good first start. We begin by applying a well-studied &lt;a href=&quot;https://en.wikipedia.org/wiki/Generalized_linear_model&quot;&gt;generalized linear model&lt;/a&gt; (GLM),
&lt;a href=&quot;https://en.wikipedia.org/wiki/Logistic_regression&quot;&gt;logistic regression&lt;/a&gt; (LR), which models a binary response random variable.
It outputs a probability, $\hat p$, for predicted membership to the positive class
as a deterministic function, $h$, of some feature embedding, $\textbf x$,
parameterized by, $\boldsymbol{\hat \theta}$, our current hypothesis.&lt;/p&gt;

\[\hat p=\\
P(\hat y=1 \space | \space \textbf x;\boldsymbol{\hat \theta})=\\
h_\boldsymbol{\hat \theta}(\textbf{x})
\tag 2 \label 2\]

&lt;p&gt;The goal of learning is to approximate nature‚Äôs hypothetical target function which maps a
full-relationship for some inputs to a true target value. Whatever your view on reality or spin on
probability, lets assume a true probabilistic binary generative process so that we can draw an
analog to the LR model. We express nature by recycling notation from \ref{2}.&lt;/p&gt;

\[p=\\
P(y=1 \space | \space \textbf x;\boldsymbol{\theta})=\\
h_\boldsymbol{\theta}(\textbf{x})
\tag 3 \label 3\]

&lt;p&gt;Fueled by data, LR learns by iteratively adjusting its model parameters, $\boldsymbol{\hat \theta}$,
so that its predictions are better aligned to nature (what‚Äôs been observed).
Specialized algorithms can be applied to guide an informative search through an
infinite-sized hypothesis (parameter) space to find a hypothesis (or the parameters) that best
reflects reality.&lt;/p&gt;

&lt;p&gt;Challenges may arise from model complexity, measurement noise, and insufficient data.
If our model is unable to capture the complexity of the target function it will fail
to generalize. If our model is overly complex, it may mistakenly learn the noise in our training 
data and fail to generalize. Moreover, if the data is not predictive, of low-quality,
or is missing, there wouldn‚Äôt be much to learn; garbage in, garbage out.&lt;/p&gt;

&lt;h2 id=&quot;definition&quot;&gt;Definition&lt;/h2&gt;

&lt;p&gt;We must carefully select an evaluation metric which enables us to measure
and compare model performance. We evaluate our model‚Äôs generalization capabilities on a
test or holdout-set of data for which the model has not been 
exposed to during training. Since we know if the user has clicked or not, we can
assess the model‚Äôs predictions against reality. A good model will be better aligned to reality.&lt;/p&gt;

&lt;p&gt;After researching many metrics,
we consider Normalized Cross-Entropy (NCE).&lt;/p&gt;

&lt;h3 id=&quot;facebook-research&quot;&gt;Facebook research&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;Normalized Cross-Entropy is equivalent to the
  average log-loss per impression divided by what the
  average log-loss per impression would be if a model predicted the
  background click through rate
  (CTR) for every impression. [1]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;variables&quot;&gt;Variables&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;$N$ is the size of the test-set (total number of ad-impressions).&lt;/li&gt;
  &lt;li&gt;$CTR$ is the observed click-through rate (proportion of clicks to ad-impressions) in the test-set.&lt;/li&gt;
  &lt;li&gt;$\hat p$, where $\{ \hat p \in \mathbb{R} \space | \space 0 \le \hat p \le 1\}$, is
our model‚Äôs predicted probability score (that the user will click).&lt;/li&gt;
  &lt;li&gt;$p$, where $p \in \{0, 1\}$, is the observed probability score (often referred to as the label).
    &lt;ul&gt;
      &lt;li&gt;1 indicates that the user did click
  (the probability of click is 1 since we‚Äôre certain they clicked);
  $P(click \space | \space user,ad)=1$.&lt;/li&gt;
      &lt;li&gt;0 indicates that the user didn‚Äôt click
  (the probability of click is 0 since we‚Äôre certain they didn‚Äôt click);
  $P(click \space | \space user,ad)=0$.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;equation&quot;&gt;Equation&lt;/h3&gt;

\[NCE=\\
\frac
{
-\frac{1}{N}\sum_{i=1}^N (p_i \cdot ln(\hat p_i) + (1-p_i) \cdot ln(1-\hat p_i))
}
{
-\frac{1}{N}\sum_{i=1}^N (p_i \cdot ln(CTR) + (1-p_i) \cdot ln(1-CTR))
}
\tag 4 \label 4\]

&lt;h2 id=&quot;what-is-log-loss&quot;&gt;What is log-loss?&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;In mathematical optimization and decision theory,
  a loss function or cost function is a function that
  maps an event or values of one or more variables onto
  a real number intuitively representing some ‚Äúcost‚Äù
  associated with the event.
  An optimization problem seeks to minimize a loss function. [7]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Log-loss can be derived from several schools of thought. In the case of binary classification,
derivations yield equivalence.&lt;/p&gt;

&lt;h3 id=&quot;probability-theory-derivation&quot;&gt;Probability Theory derivation&lt;/h3&gt;

&lt;h4 id=&quot;bernoulli&quot;&gt;Bernoulli&lt;/h4&gt;

&lt;p&gt;A user‚Äôs true click propensity for a single ad-impression, $Y$, follows a &lt;a href=&quot;https://en.wikipedia.org/wiki/Bernoulli_distribution&quot;&gt;Bernoulli distribution&lt;/a&gt;.
Since, the user will click with some probability, $p$, and 
not-click with the complement probability, $1-p$, the &lt;a href=&quot;https://en.wikipedia.org/wiki/Probability_mass_function&quot;&gt;probability mass function&lt;/a&gt; (PMF)
can be expressed in-line.&lt;/p&gt;

\[Y \sim Bernoulli(p)=\\
p^k(1-p)^{1-k} \space\space\space for \space k \in \{0, 1\}
\tag 5 \label 5\]

&lt;p&gt;GLMs relate a linear predictor to the conditional expected value of the estimated response variable
by applying a &lt;a href=&quot;https://en.wikipedia.org/wiki/Generalized_linear_model#Link_function&quot;&gt;link function&lt;/a&gt;. LR estimates the expected value of a Bernoulli-distributed response
variable by piping a linear predictor through an inverse &lt;a href=&quot;https://en.wikipedia.org/wiki/Logit&quot;&gt;logit&lt;/a&gt; link function.&lt;/p&gt;

\[\mathbb{E}[\hat Y|X]=\\
\hat p=\\
g^{-1}(X \theta)=\\
h_{\theta}(X)
\tag 6 \label 6\]

&lt;p&gt;The linear predictor is a function of some feature embedding, $\textbf x$, parameterized by a
model hypothesis, $\boldsymbol{\hat \theta}$. Per equation \ref{2}, $h$ represents the final output,
that is, after the linear transform‚Äôs output passes through the link function.&lt;/p&gt;

\[\hat Y|X \sim Bernoulli(\hat p)=\\
Bernoulli(h_\boldsymbol{\hat \theta}(\textbf x))
\tag 7 \label 7\]

&lt;p&gt;In order to estimate $p$ we invoke &lt;a href=&quot;https://en.wikipedia.org/wiki/Maximum_likelihood_estimation&quot;&gt;maximum likelihood estimation&lt;/a&gt; over our training set.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In statistics, maximum likelihood estimation (MLE) is a method of estimating
  the parameters of a probability distribution by maximizing a likelihood function,
  so that under the assumed statistical model the observed data is most probable. [8]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In order to find the maximum likelihood estimate, we must define the &lt;a href=&quot;https://en.wikipedia.org/wiki/Likelihood_function&quot;&gt;likelihood function&lt;/a&gt; 
for our data and then maximize it. The value $\hat p$ takes
at the maximum is our maximum likelihood estimate for the true parameter $p$.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In statistics, the likelihood function (often simply called the likelihood)
  measures the goodness of fit of a statistical model to a sample of data for
  given values of the unknown parameters. [9]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Generally, for a design-matrix (rows are training examples and columns are features),
$\textbf X$, and true observation matrix (associated labels), $\textbf Y$, we define the likelihood
function as the probability of the joint distribution of the training data as a function
of the parameter(s) being estimated, in our case, $\hat{\boldsymbol{\theta}}$.&lt;/p&gt;

\[\mathcal{L}(\hat{\boldsymbol{\theta}}|
\textbf X_{m \space \times \space f},\textbf Y_{m \space \times \space 1})=\\
P(\textbf X_{m \space \times \space f},\textbf Y_{m \space \times \space 1};
\hat{\boldsymbol{\theta}}) 
\tag 8 \label 8\]

&lt;p&gt;Assuming a training set of size $M$ ad-impressions that are &lt;a href=&quot;https://en.wikipedia.org/wiki/Conditional_independence&quot;&gt;conditionally independent&lt;/a&gt;
(but not identically distributed, i.e., different expected values) Bernoulli trials,
we can calculate the joint probability mass function for a given parameter,
$\hat{\boldsymbol{\theta}}$.&lt;/p&gt;

\[P(\textbf X_{m \space \times \space f},\textbf Y_{m \space \times \space 1};
\hat{\boldsymbol{\theta}})=\\
\prod_{i = 1}^{M} h_\boldsymbol{\hat \theta}(\textbf{x}_i)^{y_i}
(1-h_\boldsymbol{\hat \theta}(\textbf{x}_i))^{1-y_i}
\tag 9 \label 9\]

&lt;p&gt;The value of the joint probability mass function may get very small as multiplying
small numbers by small numbers result in even smaller numbers. At some point, we may
hit computational floating-point arithmetic underflow errors. We can instead maximize the
log of the likelihood. One benefit of the log function is that it is a monotonically
increasing function, i.e., the log-transformation preserves ordering and doesn‚Äôt
change where the maximum is. Computationally, another benefit of the log function
is that it turns repeated multiplication into a summation. The &lt;a href=&quot;https://en.wikipedia.org/wiki/List_of_logarithmic_identities&quot;&gt;list of logarithmic identities&lt;/a&gt;
is a good refresher.&lt;/p&gt;

\[ln(P(\textbf X_{m \space \times \space f},\textbf Y_{m \space \times \space 1};
\hat{\boldsymbol{\theta}}))=\\
\sum_{i = 1}^{M} {y_i} \cdot ln(h_\boldsymbol{\hat \theta}(\textbf{x}_i))
+ (1-y_i) \cdot ln(h_\boldsymbol{\hat \theta}(\textbf{x}_i))
\tag {10} \label {10}\]

&lt;p&gt;Most mathematical optimization algorithms implemented in software
are minimizers. &lt;a href=&quot;https://en.wikipedia.org/wiki/Gradient_descent&quot;&gt;Gradient descent&lt;/a&gt;, a well-suited minimization algorithm,
applies an iterative first-order hill-descent routine which converges
at a local minimum. In order to find the maximum of the log-likelihood function, we
instead find the minimum of the negative log-likelihood. Finally, we normalize by the
number of examples in the summation yielding the average log-loss. An added benefit
to the normalization is that the number of examples fed in is not a factor, i.e.,
if we wanted to compare the average log-loss over some batch size.&lt;/p&gt;

\[-\frac{1}{M}ln(P(\textbf X_{m \space \times \space f},\textbf Y_{m \space \times \space 1};
\hat{\boldsymbol{\theta}}))=\\
-\frac{1}{M}\sum_{i = 1}^{M} {y_i} \cdot ln(h_\boldsymbol{\hat \theta}(\textbf{x}_i))
+ (1-y_i) \cdot ln(h_\boldsymbol{\hat \theta}(\textbf{x}_i))
\tag {11} \label {11}\]

&lt;h4 id=&quot;binomial&quot;&gt;Binomial&lt;/h4&gt;

&lt;p&gt;Through a similar but slightly different point of view, the &lt;strong&gt;overall&lt;/strong&gt; or prior click propensity
follows a &lt;a href=&quot;https://en.wikipedia.org/wiki/Binomial_distribution&quot;&gt;Binomial distribution&lt;/a&gt;. Its PMF yields the probability of getting
exactly $k$ clicks in a series of $n$ &lt;a href=&quot;https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables&quot;&gt;independently and identically distributed&lt;/a&gt; (i.i.d)
ad-impressions (Bernoulli trials) under one common click propensity, $p$.&lt;/p&gt;

\[P(k;n,p) \sim\\
Binomial(n, k, p)=\\
\binom{n}{k} p^k(1-p)^{n-k}
\tag {12} \label {12}\]

&lt;p&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Binomial_coefficient&quot;&gt;binomial coefficient&lt;/a&gt; scales the value of the PMF by the number of combinations that $k$
clicks could have occurred within a series of $n$ ad-impressions.
Since it is a constant, it won‚Äôt have any effect on the maximum and can be safely ignored.
We‚Äôre then left with a series of i.i.d Bernoulli trials to which we can apply very similar
mathematics from the Bernoulli derivation above. Naturally, the Binomial MLE resolves to the
prior CTR, $\frac{k}{n}$. In other words, the Binomial likelihood is maximal under a fixed number of
trials at the observed success rate.&lt;/p&gt;

&lt;h3 id=&quot;information-theory-derivation&quot;&gt;Information Theory derivation&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;Information theory studies the quantification, storage, and communication of information.
  It was originally proposed by Claude Shannon in 1948 to find fundamental limits on signal
  processing and communication operations such as data compression, in a landmark paper titled
  ‚ÄúA Mathematical Theory of Communication‚Äù. [10]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;information-content&quot;&gt;Information content&lt;/h4&gt;

&lt;p&gt;Given random variable $X$ with PMF $P_{X}(x)$, we can measure the &lt;a href=&quot;https://en.wikipedia.org/wiki/Information_content#Definition&quot;&gt;information&lt;/a&gt;, $I_X$, of
outcome, $x$, as the log (usually base $e$, $2$, or $10$) inverse probability of that outcome.&lt;/p&gt;

\[I_X(x)=\\
ln(\frac{1}{P_X(x)})
\tag {13} \label {13}\]

&lt;h5 id=&quot;why-the-inverse-probability&quot;&gt;Why the inverse probability?&lt;/h5&gt;

&lt;p&gt;The inverse probability or ‚Äúsurprisal‚Äù for a given outcome is larger when the outcome is less likely
and smaller when the outcome is more likely. In other words, events that occur very frequently
don‚Äôt carry as much information as events that occur rarely. Intuitively, less-likely events
carry more information because they inform us that not only they‚Äôve occurred but that their more
likely counterparts didn‚Äôt occur. For example, when drawing a letter randomly from the 5 character
string &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ABBBB&lt;/code&gt;, the probability of drawing an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A&lt;/code&gt; is $0.2$ while the probability of drawing a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B&lt;/code&gt; is
$0.8$. If we draw &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A&lt;/code&gt;, we can eliminate $\frac{1}{.2}=5$ characters, that is, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A&lt;/code&gt; because it
occurred and all of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B&lt;/code&gt;s because we know they didn‚Äôt occur. If we draw &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B&lt;/code&gt;, we can eliminate
$\frac{1}{.8}=1.25$ characters, that is, the one and only &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A&lt;/code&gt; because we know it didn‚Äôt occur and
a quarter of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B&lt;/code&gt;s because we know one of them occurred. Since, drawing an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A&lt;/code&gt; allows us to
eliminate more characters from the string, it carries more information.&lt;/p&gt;

&lt;h5 id=&quot;why-the-logarithmic-transform&quot;&gt;Why the logarithmic transform?&lt;/h5&gt;

&lt;p&gt;Directly from &lt;a href=&quot;https://en.wikipedia.org/wiki/Claude_Shannon&quot;&gt;Claude Shannon&lt;/a&gt;‚Äôs white-paper.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The logarithmic measure is more convenient for various reasons:&lt;/p&gt;
  &lt;ol&gt;
    &lt;li&gt;It is practically more useful. Parameters of engineering importance such as time, bandwidth,
  number of relays, etc., tend to vary linearly with the logarithm of the number of possibilities.
  For example, adding one relay to a group doubles the number of possible states of the relays.
  It adds 1 to the base 2 logarithm of this number. Doubling the time roughly squares the number of
  possible messages, or doubles the logarithm, etc.&lt;/li&gt;
    &lt;li&gt;It is nearer to our intuitive feeling as to the proper measure. This is closely related to (1)
  since we intuitively measures entities by linear comparison with common standards. One feels,
  for example, that two punched cards should have twice the capacity of one for information storage,
  and two identical channels twice the capacity of one for transmitting information.&lt;/li&gt;
    &lt;li&gt;It is mathematically more suitable. Many of the limiting operations are simple in terms of the
  logarithm but would require clumsy restatement in terms of the number of possibilities. [11]&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;entropy&quot;&gt;Entropy&lt;/h4&gt;

&lt;p&gt;Entropy, $H$, is the expected value of information. For a discrete random variable, $X$, it is the
weighted average of the information of each of its outcomes.&lt;/p&gt;

\[H(X)=\\
\mathbb{E}_{x \sim P}[I_X]=\\
\sum_{i}^{N}P(x_i) \cdot ln(\frac{1}{P(x_i)})=\\
-\sum_{i}^{N}P(x_i) \cdot ln(P(x_i))
\tag {14} \label {14}\]

&lt;p&gt;Entropy can be interpreted as a measure of chaos and/or uncertainty in that it is maximized
when outcomes are equiprobable, i.e., carry the same amount of information (uniform PMF),
and minimized or $0$ when outcomes are certain. In the case of a binary random variable, it is
maximal when each outcome has a $0.5$ probability mass. It is minimized or $0$ when one of the
outcomes have a $1.0$ probability (the other having a $0.0$ probability). We can measure entropy as
the average number of bits required to encode the information content of a random variable by
substituting $log_2$ for $ln$ into \ref{14}.&lt;/p&gt;

\[-0.5 \cdot log_2(0.5)-0.5 \cdot log_2(0.5)=1
\tag {15} \label {15}\]

\[-1.0 \cdot log_2(1.0)-0.0 \cdot log_2(0.0)=\\
-0.0 \cdot log_2(0.0)-1.0 \cdot log_2(1.0)=0
\tag {16} \label {16}\]

&lt;p&gt;On average, we need one bit to represent a fair coin and no bits to represent a double-headed or
double-tailed coin because no matter what, we know the outcome. The lack of stochasticity implies
that we don‚Äôt need to flip the coin as we know the outcome a priori.&lt;/p&gt;

&lt;h4 id=&quot;cross-entropy&quot;&gt;Cross-entropy&lt;/h4&gt;

&lt;p&gt;Cross-entropy (CE) measures the expected value of information for random variable, $X$, with PMF,
$P$, using a coding scheme optimized for another, $Y$, with PMF, $Q$, over the same &lt;a href=&quot;https://en.wikipedia.org/wiki/Support_(mathematics)&quot;&gt;support&lt;/a&gt;, i.e.,
set of outcomes/events.&lt;/p&gt;

\[H(X,Y)=\\
\mathbb{E}_{x \sim P}[I_Y]=\\
\sum_{i}^{N}P(x_i) \cdot ln(\frac{1}{Q(x_i)})=\\
-\sum_{i}^{N}P(x_i) \cdot ln(Q(x_i))
\tag {17} \label {17}\]

&lt;p&gt;If $X = Y$, then CE resolves to entropy. If $X \neq Y$, CE can be expressed
in terms of entropy and Kullback‚ÄìLeibler divergence.&lt;/p&gt;

\[H(X,Y)=\\
H(X) + D_{KL}(X||Y)
\tag {18} \label {18}\]

&lt;h4 id=&quot;kullbackleibler-divergence&quot;&gt;Kullback‚ÄìLeibler divergence&lt;/h4&gt;

&lt;p&gt;Assuming random variables $X$ and $Y$ with respective PMFs $P$ and $Q$ over common support,
&lt;a href=&quot;https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence&quot;&gt;Kullback‚ÄìLeibler divergence&lt;/a&gt; (KLD) is the expected logarithmic difference between the two or
equivalently, the expected logarithm over likelihood ratios.&lt;/p&gt;

\[D_{KL}(X||Y) =\\
\mathbb{E}_{x \sim P}[ln(\frac{P(x)}{Q(x)})]=\\
\sum_{i}^{N}P(x_i) \cdot ln(\frac{P(x_i)}{Q(x_i)})
\tag {19} \label {19}\]

&lt;p&gt;It‚Äôs an asymmetric measure with a minimal value at 0, meaning the distributions are identical.
The inequality implies that KLD is not a distance metric, hence the word ‚Äúdivergence‚Äù in its name.&lt;/p&gt;

\[D_{KL}(X||Y) \neq D_{KL}(Y||X)
\tag {20} \label {20}\]

&lt;p&gt;Based on the definition of CE in \ref{18}, KLD can be understood as the average
&lt;em&gt;extra&lt;/em&gt; information required to be encoded since we‚Äôve calculated the entropy of $X$ using a
potentially suboptimal encoding scheme (from $Y$). Notice, again, if the KLD is $0$, then the
CE of $X$ is just the entropy of $X$ and that if it is $&amp;gt; 0$ then the CE of
$X$ is the entropy of $X$ plus some additional divergence, which yields a suboptimal encoding for
$X$.&lt;/p&gt;

&lt;h4 id=&quot;minimizing-cross-entropy--kullbackleibler-divergence&quot;&gt;Minimizing cross-entropy / Kullback‚ÄìLeibler divergence&lt;/h4&gt;

&lt;p&gt;LR is a &lt;a href=&quot;https://en.wikipedia.org/wiki/Supervised_learning&quot;&gt;supervised learning&lt;/a&gt; algorithm because it learns to map inputs
to outputs based on training example input-output pairs. For each training example,
the outcome has already been observed, i.e., the probability that the user clicked is either
$1.0$ or $0.0$. LR learns by comparing its prediction to the respective outcome and correcting
itself. Since both prediction and outcome binary probability distributions cover the same support,
CE applies as a measure of how close the prediction distribution is to the outcome distribution.&lt;/p&gt;

&lt;p&gt;The entropy of an observed outcome is $0$ because the act of observation collapses the probabilistic
nature of what could have happened, e.g., if a user clicked, the entropy is $0$ because there is
complete certainty the event has occurred. The same applies if the user decided not to click. See
\ref{16}. Since the entropy of the reference distribution, $X$, is $0$, we can eliminate $H(X)$ from
\ref{18} when calculating the CE. Thus, in this case, minimizing CE is equivalent to minimizing KLD.&lt;/p&gt;

\[H(X,Y)=\\
0 + D_{KL}(X||Y)=\\
D_{KL}(X||Y)
\tag {21} \label {21}\]

&lt;h4 id=&quot;cross-entropy-loss&quot;&gt;Cross-entropy loss&lt;/h4&gt;

&lt;p&gt;There‚Äôs no need to write out the mathematics for calculating CE loss over $M$ training examples
because we‚Äôve already derived it via probability theory. Minimizing the average CE of $M$ training
examples is equivalent to minimizing the negative log-likelihood of those $M$
training examples under the &lt;a href=&quot;#bernoulli&quot;&gt;Bernoulli&lt;/a&gt; model. That‚Äôs two schools of thought arriving
at the same conclusion with the same equation :P!&lt;/p&gt;

&lt;p&gt;If the connection between the two isn‚Äôt obvious, compare and contrast \ref{11} and \ref{17}. What
happens if we calculate the CE between the model‚Äôs prediction and the observed outcome
(\ref{22}/\ref{23})? What happens if we do that for all $M$ training examples and then take the
average?&lt;/p&gt;

&lt;h2 id=&quot;visualizing&quot;&gt;Visualizing‚Ä¶&lt;/h2&gt;

&lt;h3 id=&quot;log-loss--cross-entropy&quot;&gt;Log-loss / cross-entropy&lt;/h3&gt;

&lt;p&gt;CE is applied during model training/evaluation as an objective function which measures model
performance. The model learns to estimate Bernoulli distributed random
variables by iteratively comparing its estimates to natures‚Äô and penalizing itself for more costly
mistakes, i.e., the further its prediction is from what has been observed, the higher the
cost that is realized. For simplicity, let‚Äôs assume observed and estimated binary response
random variables, $Y$ and $\hat Y$ with respective PMFs $P$ and $Q$, that represent the modeled
propensity and outcome for some user clicking on some ad.&lt;/p&gt;

\[H(Y, \hat Y)=\\
-\sum_{i}^{N}P(x_i) \cdot ln(Q(x_i))
\tag {22} \label {22}\]

&lt;p&gt;Since $P(x_i)$ is always either $1.0$ or $0.0$, as it is the observed outcome, CE can be expanded
as the sum of two mutually exclusive negated log functions of which only one
gets activated according to the observed outcome. Since our model outputs the probability of a
click as $Q(x)$, the complement probability of not clicking is $1-Q(x)$.&lt;/p&gt;

\[-((P(x) \cdot ln(Q(x))) +\\
((1-P(x)) \cdot ln(1-Q(x))))=\\
\left \{
  \begin{aligned}
    &amp;amp;-ln(Q(x)), &amp;amp;&amp;amp; P(x)=1.0 \\
    &amp;amp;-ln(1-Q(x)), &amp;amp;&amp;amp; P(x)=0.0
  \end{aligned} \right.
\tag {23} \label {23}\]

&lt;p&gt;Perhaps a bit cleaner, the PMFs can be replaced with $p$ and $\hat p$ from \ref{3} and \ref{2}.&lt;/p&gt;

\[-((p \cdot ln(\hat p)) +\\
((1-p) \cdot ln(1-\hat p)))=\\
\left \{
  \begin{aligned}
    &amp;amp;-ln(\hat p), &amp;amp;&amp;amp; p=1.0 \\
    &amp;amp;-ln(1-\hat p), &amp;amp;&amp;amp; p=0.0
  \end{aligned} \right.
\tag {24} \label {24}\]

&lt;h4 id=&quot;fig-1&quot;&gt;Fig. 1&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/normalized_cross_entropy/neg_log_neg_log_reflect.png&quot; alt=&quot;neg_log_neg_log_reflect&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#fig-1&quot;&gt;Fig 1.&lt;/a&gt; [13] shows the cost our model realizes when the outcome is a click (in blue) and
not a click (in orange).&lt;/p&gt;

&lt;p&gt;If the outcome is a click (outcome probability of a click is $1.0$),
and the model predicts a probability of $1.0$, the model realizes a cost
of $0.0$, i.e., the model isn‚Äôt penalized as the prediction is perfectly reflective of the outcome.
In the case that the model predicts anything less than $1.0$, it will realize a cost that grows
exponentially as the prediction moves further away from $1.0$.&lt;/p&gt;

&lt;p&gt;If the outcome is not a click (outcome probability of a click is $0.0$), the reflection
of the same logic applies, i.e., the model must predict $0.0$ to realize a cost of $0.0$
and that cost grows exponentially as the model‚Äôs prediction moves further away from $0.0$.&lt;/p&gt;

&lt;h3 id=&quot;normalized-log-loss--cross-entropy&quot;&gt;Normalized log-loss / cross-entropy&lt;/h3&gt;

&lt;h4 id=&quot;click-through-rate-entropy&quot;&gt;Click-through rate entropy&lt;/h4&gt;

&lt;p&gt;The NCE (\ref{4}) denominator can be expressed as the entropy (\ref{14}) of the prior CTR which
is equivalent to the average log-loss if the model always predicted the CTR.&lt;/p&gt;

\[-\frac{1}{N}\sum_{i=1}^N (p_i \cdot ln(CTR) + (1-p_i) \cdot ln(1-CTR))=\\
-\frac{1}{N}\sum_{i=1}^N p_i \cdot ln(CTR)-\frac{1}{N}\sum_{i=1}^N(1-p_i) \cdot ln(1-CTR)=\\
-\sum_{i=1}^N\frac{p_i \cdot ln(CTR)}{N}-\sum_{i=1}^N\frac{(1-p_i) \cdot ln(1-CTR)}{N}=\\
-(CTR \cdot ln(CTR) + (1-CTR) \cdot ln(1-CTR))
\tag {25} \label {25}\]

&lt;h5 id=&quot;fig-2&quot;&gt;Fig. 2&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/normalized_cross_entropy/ctr_ent.png&quot; alt=&quot;ctr_ent&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#fig-2&quot;&gt;Fig. 2&lt;/a&gt; [13] shows entropy as a function of CTR. It is maximized at a CTR of
$0.5$ when clicking is just as likely as not clicking. The more the CTR drifts from $0.5$,
in either direction, the resulting entropy symmetrically decreases. At a CTR of $0.0$ or $1.0$,
the entropy would be $0.0$ as there would be complete certainty of the outcome from the data, e.g.,
only clicks or no clicks at all.&lt;/p&gt;

&lt;h5 id=&quot;fig-3&quot;&gt;Fig. 3&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/normalized_cross_entropy/prior_log_loss_sim.png&quot; alt=&quot;prior_log_loss_sim&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#fig-3&quot;&gt;Fig. 3&lt;/a&gt; [14] shows the result of a simulating \ref{25} while varying training set
size. The CE of each training example outcome, $\sim Bernoulli(0.3)$, and prediction, $0.3$ (prior),
is averaged over the $N$ prediction-outcome pairs.
As the size of the training set increases, the empirical cross-entropy converges to the expected
prior entropy of $-.3 \cdot log(.3)-(1-.3) \cdot log(1-.3)=.610$.&lt;/p&gt;

&lt;h5 id=&quot;fig-4&quot;&gt;Fig. 4&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/normalized_cross_entropy/prior_sim.png&quot; alt=&quot;prior_sim&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#fig-4&quot;&gt;Fig. 4&lt;/a&gt; [14] shows the result of a simulating the proportion of observations that
resulted in a positive label while varying training set size. The proportion converges to the
expected value as the number of trials or size of the training set increases. Since each outcome
for in a given training set size follows $Bernoulli(0.3)$, we‚Äôd expect the sampled proportion to
converge to $0.3$ as we simulate larger training set sizes.&lt;/p&gt;

&lt;p&gt;Both simulations are manifestations of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Law_of_large_numbers&quot;&gt;law of large numbers&lt;/a&gt;. As the prior converges, so does
the entropy of the prior since mathematically (\ref{25}), it is dependent on it.&lt;/p&gt;

&lt;h4 id=&quot;baseline-model&quot;&gt;Baseline model&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;When doing supervised learning, a simple sanity check consists of comparing one‚Äôs estimator
  against simple rules of thumb.&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;stratified: generates random predictions by respecting the training set class distribution.&lt;/li&gt;
    &lt;li&gt;most_frequent: always predicts the most frequent label in the training set.&lt;/li&gt;
    &lt;li&gt;prior: always predicts the class that maximizes the class prior (like most_frequent) and
predict_proba returns the class prior.&lt;/li&gt;
    &lt;li&gt;uniform: generates predictions uniformly at random.&lt;/li&gt;
    &lt;li&gt;constant: always predicts a constant label that is provided by the user. [12]&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;NCE is defined (see \ref{4}) as the predictive log-loss normalized by the log-loss of a baseline
prior model, i.e., a model which always outputs the probability of a click as the observed CTR.
One way to visualize the behavior of the normalization is to restrict the model‚Äôs predictions
to various hypothetical CTRs.&lt;/p&gt;

\[\hat p = \hat{CTR}
\tag {26} \label {26}\]

&lt;p&gt;That constraint means our model‚Äôs predictions are a constant and NCE can be broken into two
mutually exclusive terms and visualized separately.&lt;/p&gt;

\[NCE=\\
\frac
{
-\frac{1}{N}\sum_{i=1}^N (p_i \cdot ln(\hat p_i) + (1-p_i) \cdot ln(1-\hat p_i))
}
{
-\frac{1}{N}\sum_{i=1}^N (p_i \cdot ln(CTR) + (1-p_i) \cdot ln(1-CTR))
}=\\
\frac
{
-\frac{1}{N}\sum_{i=1}^N (p_i \cdot ln(\hat{CTR}) + (1-p_i) \cdot ln(1-\hat{CTR}))
}
{
-\frac{1}{N}\sum_{i=1}^N (p_i \cdot ln(CTR) + (1-p_i) \cdot ln(1-CTR))
}=\\
\frac
{
-\frac{1}{N}\sum_{i=1}^N p_i \cdot ln(\hat{CTR}) - \frac{1}{N}\sum_{i=1}^N (1-p_i) \cdot ln(1-\hat{CTR})
}
{
-\frac{1}{N}\sum_{i=1}^N p_i \cdot ln(CTR) - \frac{1}{N}\sum_{i=1}^N (1-p_i) \cdot ln(1-CTR)
}=\\
\frac
{
-\sum_{i=1}^N \frac{p_i \cdot ln(\hat{CTR})}{N} - \sum_{i=1}^N \frac{(1-p_i) \cdot ln(1-\hat{CTR})}{N}
}
{
-\sum_{i=1}^N \frac{p_i \cdot ln(CTR)}{N} - \sum_{i=1}^N \frac{(1-p_i) \cdot ln(1-CTR)}{N}
}=\\
\frac
{
-(CTR \cdot ln(\hat{CTR}) + (1-CTR) \cdot ln(1-\hat{CTR}))
}
{
-(CTR \cdot ln(CTR) + (1-CTR) \cdot ln(1-CTR))
}=\\
\frac
{
CTR \cdot ln(\hat{CTR})
}
{
CTR \cdot ln(CTR) + (1-CTR) \cdot ln(1-CTR)
}\\ + 
\frac
{
(1-CTR) \cdot ln(1-\hat{CTR})
}
{
CTR \cdot ln(CTR) + (1-CTR) \cdot ln(1-CTR)
}
\tag {27} \label {27}\]

&lt;h5 id=&quot;fig-5&quot;&gt;Fig. 5&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/normalized_cross_entropy/ctr_neg_log.png&quot; alt=&quot;ctr_neg_log&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;fig-6&quot;&gt;Fig. 6&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/normalized_cross_entropy/ctr_neg_log_reflect.png&quot; alt=&quot;ctr_neg_log_reflect&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;fig-7&quot;&gt;Fig. 7&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/normalized_cross_entropy/ctr_cross_ent.png&quot; alt=&quot;ctr_cross_ent&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#fig-7&quot;&gt;Fig. 7&lt;/a&gt; shows the CE of various baseline prior models that always predict $\hat{CTR}$ for
various observed prior $CTR$s; &lt;a href=&quot;#fig-5&quot;&gt;Fig. 5&lt;/a&gt; and &lt;a href=&quot;#fig-6&quot;&gt;Fig. 6&lt;/a&gt; show its decomposed summands.
The effect of the observed prior $CTR$ manifests as a scaling factor applied to each of the
logarithms which is exacerbated for very high and very low $CTR$s. &lt;strong&gt;Notice that the minima for each
$CTR$ curve exists at $\hat{CTR}=CTR$ while the actual minimum value changes over various&lt;/strong&gt; $CTR$s.&lt;/p&gt;

&lt;p&gt;Note that &lt;a href=&quot;#fig-7&quot;&gt;Fig. 7&lt;/a&gt; only captures the performance of baseline prior
models which are relatively weak in terms of model performance. In practice, a good model will
outperform baseline measures as it isn‚Äôt constrained to only predicting some fixed $\hat{CTR}$.&lt;/p&gt;

&lt;h5 id=&quot;fig-8&quot;&gt;Fig. 8&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/normalized_cross_entropy/CE_3D.gif&quot; alt=&quot;CE_3D&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#fig-8&quot;&gt;Fig. 8&lt;/a&gt; is a GIF of a 3D rendering of the binary CE function. Notice the two minimum
values of $0.0$ when $x$ and $y$ are both either $0.0$ or $1.0$. The animated yellow line is a
3D variation of &lt;a href=&quot;#fig-7&quot;&gt;Fig. 7&lt;/a&gt;. Click &lt;a href=&quot;https://www.math3d.org/VQVniBJh&quot;&gt;here&lt;/a&gt; to reproduce and
interact within your web browser.&lt;/p&gt;

&lt;h5 id=&quot;fig-9&quot;&gt;Fig. 9&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/normalized_cross_entropy/ctr_neg_log_norm.png&quot; alt=&quot;ctr_neg_log_norm&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;fig-10&quot;&gt;Fig. 10&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/normalized_cross_entropy/ctr_neg_log_norm_reflect.png&quot; alt=&quot;ctr_neg_log_norm_reflect&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;fig-11&quot;&gt;Fig. 11&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/normalized_cross_entropy/ctr_norm_cross_ent.png&quot; alt=&quot;ctr_norm_cross_ent&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#fig-11&quot;&gt;Fig. 11&lt;/a&gt; shows the NCE of various baseline prior models that always predict $\hat{CTR}$ for
various observed prior $CTR$s; &lt;a href=&quot;#fig-9&quot;&gt;Fig. 9&lt;/a&gt; and &lt;a href=&quot;#fig-10&quot;&gt;Fig. 10&lt;/a&gt; show its decomposed summands.
Notice that the effect of the $CTR$ is removed. &lt;strong&gt;For each $CTR$ curve, while the minima still exists
at $\hat{CTR}=CTR$, the minimum value is $1.0$ and this is the case for all&lt;/strong&gt; $CTR$s.&lt;/p&gt;

&lt;p&gt;Note that &lt;a href=&quot;#fig-11&quot;&gt;Fig. 11&lt;/a&gt; only captures the performance of baseline prior
models which are relatively weak in terms of model performance, i.e., the best model will produce a
score of $1.0$. In practice, a good model will outperform baseline measures as it isn‚Äôt
constrained to only predicting some fixed $\hat{CTR}$. This pushes the NCE theoretical lower bound
down to $0.0$ from $1.0$.&lt;/p&gt;

&lt;h5 id=&quot;fig-12&quot;&gt;Fig. 12&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/normalized_cross_entropy/NCE_3D.gif&quot; alt=&quot;NCE_3D&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#fig-12&quot;&gt;Fig. 12&lt;/a&gt; is a GIF of a 3D rendering of the binary NCE (rainbow) and CE (blue) functions.
Notice the same two minimum values of $0.0$ when $x$ and $y$ are both either $0.0$ or $1.0$.
The animated yellow line is a 3D variation of &lt;a href=&quot;#fig-7&quot;&gt;Fig. 7&lt;/a&gt;. The animated orange line is a 3D
variation of &lt;a href=&quot;#fig-11&quot;&gt;Fig. 11&lt;/a&gt;. Click &lt;a href=&quot;https://www.math3d.org/iysEN9vk&quot;&gt;here&lt;/a&gt; to reproduce and
interact within your web browser.&lt;/p&gt;

&lt;h2 id=&quot;special-thanks&quot;&gt;Special Thanks&lt;/h2&gt;

&lt;p&gt;A special thanks to &lt;a href=&quot;https://www.linkedin.com/in/cchudzicki/&quot;&gt;Chris Chudzicki&lt;/a&gt; for
his mathematics visualization tool, &lt;a href=&quot;https://www.math3d.org/&quot;&gt;Math3D&lt;/a&gt;.
It‚Äôs an excellent alternative to &lt;a href=&quot;https://www.desmos.com/&quot;&gt;Desmos&lt;/a&gt; that 
offers support for three-dimensional rendering.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;[1] X. He, J. Pan, O. Jin, T. Xu, B. Liu, T. Xu, Y. Shi, A. Atallah,
    R. Herbrich, S. Bowers, and J. Q. n. Candela. Practical
    lessons from predicting clicks on ads at facebook.
    https://research.fb.com/wp-content/uploads/2016/11/
    practical-lessons-from-predicting-clicks-on-ads-at-facebook.pdf?&lt;/p&gt;

&lt;p&gt;[2] J. Yi, Y. Chen, J. Li, S. Sett, and T. W. Yan.
    Predictive model performance: Offline and online
    evaluations.
    https://chbrown.github.io/kdd-2013-usb/kdd/p1294.pdf&lt;/p&gt;

&lt;p&gt;[3] Kamelia Aryafar, Devin Guillory, and Liangjie Hong. 2017.
    An Ensemble-based Approach to Click-Through Rate Prediction
    for Promoted Listings at Etsy.
    https://arxiv.org/pdf/1711.01377.pdf&lt;/p&gt;

&lt;p&gt;[4] V. Sreenivasan, F. Hartl. Neural Review Ranking Models for Ads at Yelp.
    https://web.stanford.edu/class/archive/cs/cs224n/
    cs224n.1174/reports/2761953.pdf&lt;/p&gt;

&lt;p&gt;[5] C. Li, Y. Lu, Q. Mei, D. Wang, S. Pandey. Click-through Prediction for
    Advertising in Twitter Timeline.
    http://www-personal.umich.edu/~qmei/pub/kdd2015-click.pdf&lt;/p&gt;

&lt;p&gt;[6] X. Ling, W. Deng, C. Gu, H. Zhou, C. Li, F. Sun. Model Ensemble for
    Click Prediction in Bing Search Ads.
    https://www.microsoft.com/en-us/research/wp-content/uploads/2017/04/main-1.pdf&lt;/p&gt;

&lt;p&gt;[7] https://en.wikipedia.org/wiki/Loss_function&lt;/p&gt;

&lt;p&gt;[8] https://en.wikipedia.org/wiki/Maximum_likelihood_estimation&lt;/p&gt;

&lt;p&gt;[9] https://en.wikipedia.org/wiki/Likelihood_function&lt;/p&gt;

&lt;p&gt;[10] https://en.wikipedia.org/wiki/Information_theory&lt;/p&gt;

&lt;p&gt;[11] C. E. Shannon. A Mathematical Theory of Communication.
     https://web.archive.org/web/19980715013250/http://cm.bell-labs.com/cm/ms/what/
     shannonday/shannon1948.pdf&lt;/p&gt;

&lt;p&gt;[12] https://scikit-learn.org/stable/modules/model_evaluation.html#dummy-estimators&lt;/p&gt;

&lt;p&gt;[13] https://github.com/daniel-deychakiwsky/notebooks/blob/master/experiments/cross_entropy_log_likelihood.ipynb&lt;/p&gt;

&lt;p&gt;[14] https://github.com/daniel-deychakiwsky/notebooks/blob/master/simulations/prior_cross_entropy_convergence_sim.ipynb&lt;/p&gt;</content><author><name>Daniel Deychakiwsky</name></author><category term="machine-learning" /><category term="artificial-intelligence" /><summary type="html">This post explores a normalized version of binary cross-entropy loss in attempt to remove the effect of the prior (class imbalance within the dataset) on the resulting value.</summary></entry><entry><title type="html">About Me</title><link href="http://localhost:4000/about-me" rel="alternate" type="text/html" title="About Me" /><published>2020-05-28T00:00:00-05:00</published><updated>2020-05-28T00:00:00-05:00</updated><id>http://localhost:4000/about-me</id><content type="html" xml:base="http://localhost:4000/about-me">&lt;p&gt;This is my first post. Here‚Äôs a bit about who I am and why I started this blog :).&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#who-am-i&quot; id=&quot;markdown-toc-who-am-i&quot;&gt;Who am I?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#why-am-i-doing-this&quot; id=&quot;markdown-toc-why-am-i-doing-this&quot;&gt;Why am I doing this?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#whats-a-deylemma&quot; id=&quot;markdown-toc-whats-a-deylemma&quot;&gt;What‚Äôs a Deylemma?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#disclaimer&quot; id=&quot;markdown-toc-disclaimer&quot;&gt;Disclaimer&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;who-am-i&quot;&gt;Who am I?&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/chucks.png&quot; alt=&quot;chucks&quot; /&gt;&lt;/p&gt;

&lt;p&gt;My name is Daniel Deychakiwsky 
(pronounced ‚Äúday-check-eve-ski‚Äù). 
The long last name is Ukrainian. Hello! –ü—Ä–∏–≤—ñ—Ç! 
Professionally by day, I‚Äôm a senior machine learning engineer.
I have about 10 years of software engineering experience,
two Bachelor of Science (BS) degrees, and a Master of Science (MS) degree.
I‚Äôm an engineer passionate for solving real world problems with 
applied artificial intelligence. I‚Äôm currently enjoying the 
intersection of deep generative learning, reinforcement learning, 
and digital signal processing.&lt;/p&gt;

&lt;h2 id=&quot;why-am-i-doing-this&quot;&gt;Why am I doing this?&lt;/h2&gt;

&lt;p&gt;As a proponent of continuous-learning,
online-education, and decentralization of knowledge,
the purpose of this blog is to share concepts that I‚Äôve found to be interesting,
practical, and application-effective. Additionally, accurately reproducing
information aids in retention of that information; in other words, I‚Äôm learning too.&lt;/p&gt;

&lt;h2 id=&quot;whats-a-deylemma&quot;&gt;What‚Äôs a Deylemma?&lt;/h2&gt;

&lt;p&gt;I named this blog by concatenating the first three letters of my last name with
the first mathematical term that came to mind that together was easy to remember.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In mathematics, informal logic and argument mapping,
a lemma is a generally minor, proven proposition which is used as a
stepping stone to a larger result.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;disclaimer&quot;&gt;Disclaimer&lt;/h2&gt;

&lt;p&gt;The content of this blog, in entirety,
is not affiliated with any of my previous 
or current employer(s).&lt;/p&gt;</content><author><name>Daniel Deychakiwsky</name></author><category term="about" /><summary type="html">This is my first post. Here‚Äôs a bit about who I am and why I started this blog :).</summary></entry></feed>